{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>CS 3780/5780 Creative Project: </h2>\n",
    "<h3>Emotion Classification of Natural Language</h3>\n",
    "\n",
    "Names and NetIDs for your group members: James Tu (jt737), Andrew Cheung (aec295)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Introduction:</h3>\n",
    "\n",
    "<p> The creative project is about conducting a real-world machine learning project on your own, with everything that is involved. Unlike in the programming projects 1-5, where we gave you all the scaffolding and you just filled in the blanks, you now start from scratch. The past programming projects provide templates for how to do this (and you can reuse part of your code if you wish), and the lectures provide some of the methods you can use. So, this creative project brings realism to how you will use machine learning in the real world.  </p>\n",
    "\n",
    "The task you will work on is classifying texts to human emotions. Through words, humans express feelings, articulate thoughts, and communicate our deepest needs and desires. Language helps us interpret the nuances of joy, sadness, anger, and love, allowing us to connect with others on a deeper level. Are you able to train an ML model that recognizes the human emotions expressed in a piece of text? <b>Please read the project description PDF file carefully and follow the instructions there. Also make sure you write your code and answers to all the questions in this Jupyter Notebook </b> </p>\n",
    "<p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 0: Basics</h2><p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>0.1 Import:</h3><p>\n",
    "Please import necessary packages to use. Note that learning and using packages are recommended but not required for this project. Some official tutorial for suggested packacges includes:\n",
    "    \n",
    "https://scikit-learn.org/stable/tutorial/basic/tutorial.html\n",
    "    \n",
    "https://pytorch.org/tutorials/\n",
    "    \n",
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>0.2 Accuracy and Mean Squared Error:</h3><p>\n",
    "To measure your performance in the Kaggle Competition, we are using accuracy. As a recap, accuracy is the percent of labels you predict correctly. To measure this, you can use library functions from sklearn. A simple example is shown below. \n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42857142857142855"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = [3, 2, 1, 0, 1, 2, 3]\n",
    "y_true = [0, 1, 2, 3, 1, 2, 3]\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 1: Basic</h2><p>\n",
    "Note that your code should be commented well and in part 1.4 you can refer to your comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.1 Load and preprocess the dataset:</h3><p>\n",
    "We provide how to load the data on Kaggle's Notebook.\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "# Split into text and label\n",
    "train_text = train[\"text\"]\n",
    "train_label = train[\"label\"]\n",
    "\n",
    "# Load the testing data\n",
    "test = pd.read_csv(\"../data/test.csv\")\n",
    "# Split into text and id\n",
    "test_id = test[\"id\"]\n",
    "test_text = test[\"text\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i interact with on a daily basis either in rea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger than fiction. Can't even begin to com...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i sit here with the aftermath feeling so damn ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Great job! Hats off to you.</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i hate you threads posted by people just whini...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  i interact with on a daily basis either in rea...      1\n",
       "1  Stranger than fiction. Can't even begin to com...      1\n",
       "2  i sit here with the aftermath feeling so damn ...      1\n",
       "3                        Great job! Hats off to you.     25\n",
       "4  i hate you threads posted by people just whini...      9"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head() # Show the first few rows of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>im feeling like a hot potato right now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>i feel that are becoming impressed upon my lit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>id ever held any girls hand but boy did i sure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>i feel thats when i feel my grief over the bra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>i feel will never been resolved in a way to ke...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text\n",
       "0   0             im feeling like a hot potato right now\n",
       "1   1  i feel that are becoming impressed upon my lit...\n",
       "2   2  id ever held any girls hand but boy did i sure...\n",
       "3   3  i feel thats when i feel my grief over the bra...\n",
       "4   4  i feel will never been resolved in a way to ke..."
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head() # Show the first few rows of testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.2 Use At Least Two Training Algorithms from class:</h3><p>\n",
    "You need to use at least two training algorithms from class. You can use your code from previous projects or any packages you imported in part 0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.3 Training, Validation and Model Selection:</h3><p>\n",
    "You need to split your data to a training set and validation set or performing a cross-validation for model selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we split our data into a training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_val = train_test_split(train_text, train_label, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we vectorize the training text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer_tfidf = TfidfVectorizer(stop_words='english') # Remove stop words\n",
    "vectorizer_bow = CountVectorizer(stop_words='english') # Remove stop words\n",
    "\n",
    "# Use TF-IDF vectorizer for sentence embeddings\n",
    "X_train_tfidf = vectorizer_tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer_tfidf.transform(X_test)\n",
    "\n",
    "# Use bag of words vectorizer for sentence embeddings\n",
    "X_train_bow = vectorizer_bow.fit_transform(X_train)\n",
    "X_test_bow = vectorizer_bow.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3.1 Training the SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/my_env/lib/python3.8/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 11\u001b[0m\n\u001b[1;32m      5\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m],\n\u001b[1;32m      7\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoly\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      8\u001b[0m }\n\u001b[1;32m     10\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(SVC(), params, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_tfidf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Print the best parameters found by GridSearchCV\u001b[39;00m\n\u001b[1;32m     14\u001b[0m best_params \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/my_env/lib/python3.8/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/my_env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/my_env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/my_env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/my_env/lib/python3.8/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/my_env/lib/python3.8/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/my_env/lib/python3.8/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/my_env/lib/python3.8/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/my_env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:732\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    730\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 732\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    736\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/my_env/lib/python3.8/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/my_env/lib/python3.8/site-packages/sklearn/svm/_base.py:250\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    249\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[0;32m--> 250\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/my_env/lib/python3.8/site-packages/sklearn/svm/_base.py:371\u001b[0m, in \u001b[0;36mBaseLibSVM._sparse_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    357\u001b[0m kernel_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_kernels\u001b[38;5;241m.\u001b[39mindex(kernel)\n\u001b[1;32m    359\u001b[0m libsvm_sparse\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[1;32m    361\u001b[0m (\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[1;32m    364\u001b[0m     dual_coef_data,\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[0;32m--> 371\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mlibsvm_sparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibsvm_sparse_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# TODO(1.4): Replace \"_class_weight\" with \"class_weight_\"\u001b[39;49;00m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_class_weight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshrinking\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobability\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclasses_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32msklearn/svm/_libsvm_sparse.pyx:219\u001b[0m, in \u001b[0;36msklearn.svm._libsvm_sparse.libsvm_sparse_train\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/my_env/lib/python3.8/site-packages/scipy/sparse/_compressed.py:26\u001b[0m, in \u001b[0;36m_cs_matrix.__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_cs_matrix\u001b[39;00m(_data_matrix, _minmax_mixin, IndexMixin):\n\u001b[1;32m     24\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"base matrix class for compressed row- and column-oriented matrices\"\"\"\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg1, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     27\u001b[0m         _data_matrix\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m isspmatrix(arg1):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Use grid search to find the best hyperparameters for SVM model\n",
    "params = {\n",
    "  'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "  'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(), params, scoring='accuracy', verbose=1)\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Print the best parameters found by GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "\n",
    "best_C, best_kernal = best_params['C'], best_params['kernel']\n",
    "\n",
    "# Train SVM model\n",
    "svm_model = SVC(kernel=best_kernal, C=best_C)\n",
    "svm_model.fit(X_train_tfidf, y_train) # Use TF-IDF embeddings for SVM\n",
    "\n",
    "# Predict and calculate accuracy for SVM model\n",
    "y_pred = svm_model.predict(X_test_tfidf)\n",
    "accuracy_svm = accuracy_score(y_val, y_pred)\n",
    "\n",
    "print(f'SVM Accuracy: {accuracy_svm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3.2 Training the Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/my_env/lib/python3.8/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.2\n",
      "Naive Bayes Accuracy: 0.5895\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Use grid search to find the best hyperparameters (alpha for Laplace smoothing) for Naive Bayes\n",
    "params = {'alpha': [0.1 * x for x in range(1, 11)]} # Search alpha values 0.1 to 1\n",
    "grid_search = GridSearchCV(MultinomialNB(), params, scoring='accuracy')\n",
    "grid_search.fit(X_train_bow, y_train)\n",
    "\n",
    "best_alpha = grid_search.best_params_['alpha'] # Get the best alpha value\n",
    "print(f\"Best alpha: {best_alpha}\")\n",
    "\n",
    "nb_model = MultinomialNB(alpha=best_alpha) # Use the best alpha value for Naive Bayes Model\n",
    "nb_model.fit(X_train_bow, y_train) # Use bag of words embeddings for Naive Bayes\n",
    "\n",
    "# Predict and calculate accuracy for Naive Bayes model\n",
    "y_pred_nb = nb_model.predict(X_test_bow)\n",
    "accuracy_nb = accuracy_score(y_val, y_pred_nb) \n",
    "print(f'Naive Bayes Accuracy: {accuracy_nb}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.4 Explanation in Words:</h3><p>\n",
    "    You need to answer the following questions in the markdown cell after this cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4.1 How did you formulate the learning problem?\n",
    "\n",
    "We formulated the learning problem as a text classification problem where we are \n",
    "given an input text and our goal is to predict the emotion of the text. In particular, \n",
    "we are given an input text as a string and our goal is to classify the text into 1 of\n",
    "28 different classes (labeled 0 to 27) representing the semantic emotion of the text. Hence, we formulated\n",
    "this learning problem as a multi-class classification problem.\n",
    "\n",
    "In order to make the text input useful for machine learning, we need to transform the input\n",
    "text into vector representations that can be used by our training algorithms. There are several ways\n",
    "we can vectorize our text, but we decided to use the TF-IDF and Bag of Words vectorization\n",
    "methods, which we will explain why later on when explain the our model selection. \n",
    "The Bag of Words embeddings represent text as vectors of word frequencies, but doesn't consider\n",
    "the order of words. On the other hand, TF-IDF embeddings weight the frequency of words\n",
    "against how often they appear, which highlights more unique words and reduces the weight\n",
    "of commonly used words. To perform these sentence embeddings, we used the sci-kit learn's\n",
    "TfidfVectorizer and CounterVectorizer, which handles the tokenization of the input text and vector output.\n",
    "When tokenizing the text, for both vectorizers, we decided to exclude stop words like \"and\" and \"the\" as they\n",
    "do not contribute much to the emotion of a text and can add noise to our vector representations.\n",
    "\n",
    "1.4.2 Which two learning methods from class did you choose and why did you made the choices?\n",
    "\n",
    "For the two learning methods from class, we decided to use the SVM and Naive Bayes training algorithms. \n",
    "While researching which algorithms to use for this text classification problem, we came across the paper\n",
    "\"Text Categorization with Support Vector Machines\" by Thorsten Joachims. In the paper, Joachims \n",
    "explores how SVMs are particularly effective at text categorization problems. In particular, \n",
    "the paper argues that SVMs are well suited for text categorization since they can \n",
    "handle high-dimensional features spaces well, which is common in text data. Additionally,\n",
    "the paper explain how many text classification problems are linearly seperable in high-dimensional\n",
    "feature space, which would make SVMs more effective by maximizing margins between classes. For these reasons,\n",
    "we decided to use SVM as one of our learning methods. For the vector embeddings used as inputs\n",
    "to the SVM model, we chose to use the TF-IDF embeddings since they provide normalized\n",
    "weights for terms, which would help prevent the decision boundaries from being skewed. \n",
    "\n",
    "For the second learning method, we decided to use Naive Bayes since we felt that it\n",
    "was the most intuitive. The Naive Bayes training algorithm assumes that the \n",
    "features, which in this case are the words, are conditionally independent given the\n",
    "label, which means that the presence or frequency of a word contributes independently \n",
    "to determining the label. Intuitively, text withs words that appear more frequently in a \n",
    "text of a certain label should have a higher probability of being assigned that label.\n",
    "However, we are aware that this assumption of feature independence most likely\n",
    "will not hold for most text since words in text are often correlated, combining to \n",
    "create emotion. While we predict that Naive Bayes would be less effective than SVM due\n",
    "to its relative simplicity, we decided to use Naive Bayes as a baseline for the\n",
    "other text classification methods. For the Naive Bayes model, we used the bag \n",
    "of words embeddings instead of TF-IDF used with the SVM model. \n",
    "This is because Naive Bayes assumes that the features are conditionally\n",
    "independent given the class label, which aligns with the bag of words embeddings,\n",
    "since it only represents the frequency of the terms and doesn't add any additional\n",
    "weights. Hence the freqency of each word in the bag of words embeddings are\n",
    "directly interpreted as a probabilities by the model. \n",
    "\n",
    "1.4.3 How did you do the model selection?\n",
    "\n",
    "For both SVM and Naive Bayes models, we did hyperparameter tuning to find the best hyperparameters.\n",
    "In particular, we used GridSearchCV to find the best hyperparameters for each model based\n",
    "on cross-validated accuracy scores. For the SVM, we tuned two parameters: C and the kernel. \n",
    "For the C value, we tested the values: [0.001, 0.01, 0.1, 1, 10]. We chose\n",
    "these values as they provide a wide range of C values and we limited the highest C\n",
    "to 10 since we didn't want to choose a C that would overfit the training examples\n",
    "too much, as a higher C value caused the model to place more importance on minimizing \n",
    "misclassifications on the training data. For the kernel, we tested the values \n",
    "['linear', 'poly', 'rbf', 'sigmoid'] as these we the kernels types that were\n",
    "specificed on the scikit learn SVM model. Based on our hyperparameter tuning\n",
    "we discovered that C = 1 and kernel = 'linear' achieved the highest accuracy on our validation set, so we \n",
    "selected those values for our SVM model evaluated on the test set. \n",
    "\n",
    "For the Naive Bayes model, we tuned the alpha parameter, which controls the\n",
    "Laplace smoothing, which ensures that there are no zero probabilities for words\n",
    "that are not in the training data. Using scikit learn's GridSearchCV, we tested\n",
    "alpha values from [0.1, 0.2, ..., 1]. We decided to test small alpha values since\n",
    "we wanted our model to be more sensitive to distinguishing features, which\n",
    "we predicted would enable our model to more easily differentiate between\n",
    "different emotions. Based on our results from GridSearchCV, we discovered that\n",
    "alpha = 0.2 was the most effective on our validation set, so we selected that\n",
    "alpha for the Naive Bayes model evaluated on the test set.\n",
    "\n",
    "1.4.4 Does the test performance reach the first baseline \"Tiny Piney\"? (Please include a screenshot of Kaggle Submission)\n",
    "\n",
    "For the Naive Bayes model, our submission (nb_predictions.csv) did not reach the first baseline \"Tiney Piney\":\n",
    "![Naive Bayes Accuracy](../images/NaiveBayes_Accuracy.png)\n",
    "\n",
    "For the SVM model (predictions.csv), we did reach the first baseline \"Tiney Piney\":\n",
    "![SVM Accuracy](../images/SVM_Accuracy.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 2: Be creative!</h2><p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.1 Open-ended Code:</h3><p>\n",
    "You may follow the steps in part 1 again but making innovative changes like using new training algorithms, etc. Make sure you explain everything clearly in part 2.2. Note that beating \"Zero Hero\" is only a small portion of this part. Any creative ideas will receive most points as long as they are reasonable and clearly explained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/ml_final_project_env/lib/python3.8/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml_final_project_env/lib/python3.8/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a7466e3110d42048d43487785c55657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.2984, 'grad_norm': 8.51846694946289, 'learning_rate': 6.000000000000001e-07, 'epoch': 0.02}\n",
      "{'loss': 3.3467, 'grad_norm': 8.14156436920166, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.04}\n",
      "{'loss': 3.3273, 'grad_norm': 6.981070041656494, 'learning_rate': 1.8e-06, 'epoch': 0.06}\n",
      "{'loss': 3.2718, 'grad_norm': 6.977924346923828, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.08}\n",
      "{'loss': 3.2542, 'grad_norm': 5.438112258911133, 'learning_rate': 3e-06, 'epoch': 0.1}\n",
      "{'loss': 3.2424, 'grad_norm': 8.57590389251709, 'learning_rate': 3.6e-06, 'epoch': 0.12}\n",
      "{'loss': 3.1999, 'grad_norm': 7.2673139572143555, 'learning_rate': 4.2000000000000004e-06, 'epoch': 0.14}\n",
      "{'loss': 3.1454, 'grad_norm': 6.323453903198242, 'learning_rate': 4.800000000000001e-06, 'epoch': 0.16}\n",
      "{'loss': 3.0875, 'grad_norm': 7.2788543701171875, 'learning_rate': 5.4e-06, 'epoch': 0.18}\n",
      "{'loss': 2.9809, 'grad_norm': 6.578875541687012, 'learning_rate': 6e-06, 'epoch': 0.2}\n",
      "{'loss': 2.9202, 'grad_norm': 8.300263404846191, 'learning_rate': 6.6e-06, 'epoch': 0.22}\n",
      "{'loss': 2.7747, 'grad_norm': 7.049148082733154, 'learning_rate': 7.2e-06, 'epoch': 0.24}\n",
      "{'loss': 2.6848, 'grad_norm': 5.765585899353027, 'learning_rate': 7.8e-06, 'epoch': 0.26}\n",
      "{'loss': 2.6669, 'grad_norm': 5.6953816413879395, 'learning_rate': 8.400000000000001e-06, 'epoch': 0.28}\n",
      "{'loss': 2.4741, 'grad_norm': 5.290677547454834, 'learning_rate': 9e-06, 'epoch': 0.3}\n",
      "{'loss': 2.3526, 'grad_norm': 6.412012577056885, 'learning_rate': 9.600000000000001e-06, 'epoch': 0.32}\n",
      "{'loss': 2.5901, 'grad_norm': 7.36713981628418, 'learning_rate': 1.02e-05, 'epoch': 0.34}\n",
      "{'loss': 2.3472, 'grad_norm': 6.995358943939209, 'learning_rate': 1.08e-05, 'epoch': 0.36}\n",
      "{'loss': 2.2497, 'grad_norm': 8.185684204101562, 'learning_rate': 1.1400000000000001e-05, 'epoch': 0.38}\n",
      "{'loss': 2.1735, 'grad_norm': 6.3505353927612305, 'learning_rate': 1.2e-05, 'epoch': 0.4}\n",
      "{'loss': 2.093, 'grad_norm': 5.0375590324401855, 'learning_rate': 1.26e-05, 'epoch': 0.42}\n",
      "{'loss': 2.0479, 'grad_norm': 6.101330757141113, 'learning_rate': 1.32e-05, 'epoch': 0.44}\n",
      "{'loss': 2.0811, 'grad_norm': 15.338143348693848, 'learning_rate': 1.3800000000000002e-05, 'epoch': 0.46}\n",
      "{'loss': 1.8397, 'grad_norm': 7.2765984535217285, 'learning_rate': 1.44e-05, 'epoch': 0.48}\n",
      "{'loss': 2.0597, 'grad_norm': 11.70578670501709, 'learning_rate': 1.5e-05, 'epoch': 0.5}\n",
      "{'loss': 1.823, 'grad_norm': 8.254432678222656, 'learning_rate': 1.56e-05, 'epoch': 0.52}\n",
      "{'loss': 2.0489, 'grad_norm': 8.705217361450195, 'learning_rate': 1.62e-05, 'epoch': 0.54}\n",
      "{'loss': 1.9843, 'grad_norm': 9.329057693481445, 'learning_rate': 1.6800000000000002e-05, 'epoch': 0.56}\n",
      "{'loss': 1.8551, 'grad_norm': 7.63995885848999, 'learning_rate': 1.74e-05, 'epoch': 0.58}\n",
      "{'loss': 1.6169, 'grad_norm': 7.476352691650391, 'learning_rate': 1.8e-05, 'epoch': 0.6}\n",
      "{'loss': 1.7956, 'grad_norm': 4.447920322418213, 'learning_rate': 1.86e-05, 'epoch': 0.62}\n",
      "{'loss': 1.6197, 'grad_norm': 10.117470741271973, 'learning_rate': 1.9200000000000003e-05, 'epoch': 0.64}\n",
      "{'loss': 1.5898, 'grad_norm': 7.394019603729248, 'learning_rate': 1.98e-05, 'epoch': 0.66}\n",
      "{'loss': 1.7067, 'grad_norm': 14.193587303161621, 'learning_rate': 2.04e-05, 'epoch': 0.68}\n",
      "{'loss': 1.4605, 'grad_norm': 6.5791521072387695, 'learning_rate': 2.1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.5346, 'grad_norm': 6.263856887817383, 'learning_rate': 2.16e-05, 'epoch': 0.72}\n",
      "{'loss': 1.6529, 'grad_norm': 5.622711658477783, 'learning_rate': 2.22e-05, 'epoch': 0.74}\n",
      "{'loss': 1.4684, 'grad_norm': 7.3777174949646, 'learning_rate': 2.2800000000000002e-05, 'epoch': 0.76}\n",
      "{'loss': 1.3516, 'grad_norm': 10.655315399169922, 'learning_rate': 2.3400000000000003e-05, 'epoch': 0.78}\n",
      "{'loss': 1.334, 'grad_norm': 7.851449966430664, 'learning_rate': 2.4e-05, 'epoch': 0.8}\n",
      "{'loss': 1.2578, 'grad_norm': 9.067131996154785, 'learning_rate': 2.4599999999999998e-05, 'epoch': 0.82}\n",
      "{'loss': 1.2409, 'grad_norm': 15.565056800842285, 'learning_rate': 2.52e-05, 'epoch': 0.84}\n",
      "{'loss': 1.5351, 'grad_norm': 9.520278930664062, 'learning_rate': 2.58e-05, 'epoch': 0.86}\n",
      "{'loss': 1.43, 'grad_norm': 5.949849605560303, 'learning_rate': 2.64e-05, 'epoch': 0.88}\n",
      "{'loss': 1.2453, 'grad_norm': 7.509220600128174, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.9}\n",
      "{'loss': 1.16, 'grad_norm': 8.615103721618652, 'learning_rate': 2.7600000000000003e-05, 'epoch': 0.92}\n",
      "{'loss': 1.1925, 'grad_norm': 26.430212020874023, 'learning_rate': 2.8199999999999998e-05, 'epoch': 0.94}\n",
      "{'loss': 1.2039, 'grad_norm': 11.629302978515625, 'learning_rate': 2.88e-05, 'epoch': 0.96}\n",
      "{'loss': 1.2138, 'grad_norm': 11.51854133605957, 'learning_rate': 2.94e-05, 'epoch': 0.98}\n",
      "{'loss': 1.1038, 'grad_norm': 8.619799613952637, 'learning_rate': 3e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec43eb157d8b48a684bc48e91f31138d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0602117776870728, 'eval_accuracy': 0.734, 'eval_runtime': 13.3322, 'eval_samples_per_second': 150.012, 'eval_steps_per_second': 2.4, 'epoch': 1.0}\n",
      "{'loss': 0.9514, 'grad_norm': 13.998128890991211, 'learning_rate': 2.97e-05, 'epoch': 1.02}\n",
      "{'loss': 0.9016, 'grad_norm': 16.119165420532227, 'learning_rate': 2.94e-05, 'epoch': 1.04}\n",
      "{'loss': 1.0605, 'grad_norm': 6.240468978881836, 'learning_rate': 2.91e-05, 'epoch': 1.06}\n",
      "{'loss': 0.9469, 'grad_norm': 6.595391273498535, 'learning_rate': 2.88e-05, 'epoch': 1.08}\n",
      "{'loss': 0.8084, 'grad_norm': 10.609246253967285, 'learning_rate': 2.8499999999999998e-05, 'epoch': 1.1}\n",
      "{'loss': 0.9298, 'grad_norm': 8.373117446899414, 'learning_rate': 2.8199999999999998e-05, 'epoch': 1.12}\n",
      "{'loss': 0.9939, 'grad_norm': 16.88282012939453, 'learning_rate': 2.79e-05, 'epoch': 1.14}\n",
      "{'loss': 0.9741, 'grad_norm': 13.239126205444336, 'learning_rate': 2.7600000000000003e-05, 'epoch': 1.16}\n",
      "{'loss': 0.8263, 'grad_norm': 6.418806076049805, 'learning_rate': 2.7300000000000003e-05, 'epoch': 1.18}\n",
      "{'loss': 0.8794, 'grad_norm': 9.735480308532715, 'learning_rate': 2.7000000000000002e-05, 'epoch': 1.2}\n",
      "{'loss': 0.8711, 'grad_norm': 10.743267059326172, 'learning_rate': 2.6700000000000002e-05, 'epoch': 1.22}\n",
      "{'loss': 0.8796, 'grad_norm': 3.7497143745422363, 'learning_rate': 2.64e-05, 'epoch': 1.24}\n",
      "{'loss': 1.05, 'grad_norm': 10.221442222595215, 'learning_rate': 2.61e-05, 'epoch': 1.26}\n",
      "{'loss': 1.0209, 'grad_norm': 8.575576782226562, 'learning_rate': 2.58e-05, 'epoch': 1.28}\n",
      "{'loss': 0.776, 'grad_norm': 4.284636974334717, 'learning_rate': 2.55e-05, 'epoch': 1.3}\n",
      "{'loss': 0.8938, 'grad_norm': 7.32307767868042, 'learning_rate': 2.52e-05, 'epoch': 1.32}\n",
      "{'loss': 0.8518, 'grad_norm': 7.618556976318359, 'learning_rate': 2.49e-05, 'epoch': 1.34}\n",
      "{'loss': 1.1008, 'grad_norm': 2.958815097808838, 'learning_rate': 2.4599999999999998e-05, 'epoch': 1.36}\n",
      "{'loss': 0.964, 'grad_norm': 5.0465006828308105, 'learning_rate': 2.43e-05, 'epoch': 1.38}\n",
      "{'loss': 0.8738, 'grad_norm': 7.186373710632324, 'learning_rate': 2.4e-05, 'epoch': 1.4}\n",
      "{'loss': 0.8359, 'grad_norm': 4.160459995269775, 'learning_rate': 2.37e-05, 'epoch': 1.42}\n",
      "{'loss': 0.8131, 'grad_norm': 5.2743821144104, 'learning_rate': 2.3400000000000003e-05, 'epoch': 1.44}\n",
      "{'loss': 1.0018, 'grad_norm': 4.961529731750488, 'learning_rate': 2.3100000000000002e-05, 'epoch': 1.46}\n",
      "{'loss': 0.7546, 'grad_norm': 6.671510219573975, 'learning_rate': 2.2800000000000002e-05, 'epoch': 1.48}\n",
      "{'loss': 0.8364, 'grad_norm': 10.013914108276367, 'learning_rate': 2.25e-05, 'epoch': 1.5}\n",
      "{'loss': 0.8954, 'grad_norm': 5.900457859039307, 'learning_rate': 2.22e-05, 'epoch': 1.52}\n",
      "{'loss': 0.9751, 'grad_norm': 11.070351600646973, 'learning_rate': 2.19e-05, 'epoch': 1.54}\n",
      "{'loss': 0.8496, 'grad_norm': 6.741128921508789, 'learning_rate': 2.16e-05, 'epoch': 1.56}\n",
      "{'loss': 0.8025, 'grad_norm': 7.483889579772949, 'learning_rate': 2.13e-05, 'epoch': 1.58}\n",
      "{'loss': 0.9226, 'grad_norm': 6.726629734039307, 'learning_rate': 2.1e-05, 'epoch': 1.6}\n",
      "{'loss': 0.7265, 'grad_norm': 4.98504114151001, 'learning_rate': 2.07e-05, 'epoch': 1.62}\n",
      "{'loss': 0.9772, 'grad_norm': 11.5733642578125, 'learning_rate': 2.04e-05, 'epoch': 1.64}\n",
      "{'loss': 0.8828, 'grad_norm': 5.458413600921631, 'learning_rate': 2.01e-05, 'epoch': 1.66}\n",
      "{'loss': 0.6702, 'grad_norm': 7.50275993347168, 'learning_rate': 1.98e-05, 'epoch': 1.68}\n",
      "{'loss': 0.857, 'grad_norm': 7.667361259460449, 'learning_rate': 1.95e-05, 'epoch': 1.7}\n",
      "{'loss': 0.9895, 'grad_norm': 3.9242568016052246, 'learning_rate': 1.9200000000000003e-05, 'epoch': 1.72}\n",
      "{'loss': 0.7367, 'grad_norm': 7.282572269439697, 'learning_rate': 1.8900000000000002e-05, 'epoch': 1.74}\n",
      "{'loss': 0.8138, 'grad_norm': 6.129001617431641, 'learning_rate': 1.86e-05, 'epoch': 1.76}\n",
      "{'loss': 0.916, 'grad_norm': 7.16874361038208, 'learning_rate': 1.83e-05, 'epoch': 1.78}\n",
      "{'loss': 0.8766, 'grad_norm': 8.871437072753906, 'learning_rate': 1.8e-05, 'epoch': 1.8}\n",
      "{'loss': 0.9193, 'grad_norm': 14.935744285583496, 'learning_rate': 1.77e-05, 'epoch': 1.82}\n",
      "{'loss': 0.9571, 'grad_norm': 6.751887798309326, 'learning_rate': 1.74e-05, 'epoch': 1.84}\n",
      "{'loss': 0.7615, 'grad_norm': 7.31272029876709, 'learning_rate': 1.71e-05, 'epoch': 1.86}\n",
      "{'loss': 0.8684, 'grad_norm': 7.640933036804199, 'learning_rate': 1.6800000000000002e-05, 'epoch': 1.88}\n",
      "{'loss': 0.7284, 'grad_norm': 21.349985122680664, 'learning_rate': 1.65e-05, 'epoch': 1.9}\n",
      "{'loss': 0.7895, 'grad_norm': 8.284541130065918, 'learning_rate': 1.62e-05, 'epoch': 1.92}\n",
      "{'loss': 0.889, 'grad_norm': 4.986594200134277, 'learning_rate': 1.59e-05, 'epoch': 1.94}\n",
      "{'loss': 0.8936, 'grad_norm': 23.254436492919922, 'learning_rate': 1.56e-05, 'epoch': 1.96}\n",
      "{'loss': 0.883, 'grad_norm': 8.630845069885254, 'learning_rate': 1.53e-05, 'epoch': 1.98}\n",
      "{'loss': 1.0478, 'grad_norm': 16.513362884521484, 'learning_rate': 1.5e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "741f863d65ef43fc954f07831cf70225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8267295956611633, 'eval_accuracy': 0.7705, 'eval_runtime': 14.7733, 'eval_samples_per_second': 135.379, 'eval_steps_per_second': 2.166, 'epoch': 2.0}\n",
      "{'loss': 0.8446, 'grad_norm': 7.037771701812744, 'learning_rate': 1.47e-05, 'epoch': 2.02}\n",
      "{'loss': 0.5949, 'grad_norm': 7.231054306030273, 'learning_rate': 1.44e-05, 'epoch': 2.04}\n",
      "{'loss': 0.5732, 'grad_norm': 2.1377882957458496, 'learning_rate': 1.4099999999999999e-05, 'epoch': 2.06}\n",
      "{'loss': 0.4948, 'grad_norm': 3.770707845687866, 'learning_rate': 1.3800000000000002e-05, 'epoch': 2.08}\n",
      "{'loss': 0.5399, 'grad_norm': 6.750439643859863, 'learning_rate': 1.3500000000000001e-05, 'epoch': 2.1}\n",
      "{'loss': 0.7615, 'grad_norm': 3.45353364944458, 'learning_rate': 1.32e-05, 'epoch': 2.12}\n",
      "{'loss': 0.7399, 'grad_norm': 8.158562660217285, 'learning_rate': 1.29e-05, 'epoch': 2.14}\n",
      "{'loss': 0.6784, 'grad_norm': 8.884299278259277, 'learning_rate': 1.26e-05, 'epoch': 2.16}\n",
      "{'loss': 0.7153, 'grad_norm': 11.869548797607422, 'learning_rate': 1.2299999999999999e-05, 'epoch': 2.18}\n",
      "{'loss': 0.5933, 'grad_norm': 5.751962184906006, 'learning_rate': 1.2e-05, 'epoch': 2.2}\n",
      "{'loss': 0.8159, 'grad_norm': 12.179814338684082, 'learning_rate': 1.1700000000000001e-05, 'epoch': 2.22}\n",
      "{'loss': 0.498, 'grad_norm': 3.6280431747436523, 'learning_rate': 1.1400000000000001e-05, 'epoch': 2.24}\n",
      "{'loss': 0.5327, 'grad_norm': 11.742799758911133, 'learning_rate': 1.11e-05, 'epoch': 2.26}\n",
      "{'loss': 0.6146, 'grad_norm': 7.279242038726807, 'learning_rate': 1.08e-05, 'epoch': 2.28}\n",
      "{'loss': 0.7095, 'grad_norm': 4.263050556182861, 'learning_rate': 1.05e-05, 'epoch': 2.3}\n",
      "{'loss': 0.7243, 'grad_norm': 2.596003532409668, 'learning_rate': 1.02e-05, 'epoch': 2.32}\n",
      "{'loss': 0.5831, 'grad_norm': 5.008797645568848, 'learning_rate': 9.9e-06, 'epoch': 2.34}\n",
      "{'loss': 0.5492, 'grad_norm': 6.487926006317139, 'learning_rate': 9.600000000000001e-06, 'epoch': 2.36}\n",
      "{'loss': 0.6135, 'grad_norm': 3.360560178756714, 'learning_rate': 9.3e-06, 'epoch': 2.38}\n",
      "{'loss': 0.6775, 'grad_norm': 13.88671588897705, 'learning_rate': 9e-06, 'epoch': 2.4}\n",
      "{'loss': 0.6844, 'grad_norm': 5.127561092376709, 'learning_rate': 8.7e-06, 'epoch': 2.42}\n",
      "{'loss': 0.4784, 'grad_norm': 8.184867858886719, 'learning_rate': 8.400000000000001e-06, 'epoch': 2.44}\n",
      "{'loss': 0.6445, 'grad_norm': 2.561152219772339, 'learning_rate': 8.1e-06, 'epoch': 2.46}\n",
      "{'loss': 0.608, 'grad_norm': 11.200785636901855, 'learning_rate': 7.8e-06, 'epoch': 2.48}\n",
      "{'loss': 0.6709, 'grad_norm': 4.63131856918335, 'learning_rate': 7.5e-06, 'epoch': 2.5}\n",
      "{'loss': 0.6773, 'grad_norm': 4.6323370933532715, 'learning_rate': 7.2e-06, 'epoch': 2.52}\n",
      "{'loss': 0.6569, 'grad_norm': 9.995645523071289, 'learning_rate': 6.900000000000001e-06, 'epoch': 2.54}\n",
      "{'loss': 0.5853, 'grad_norm': 7.761476516723633, 'learning_rate': 6.6e-06, 'epoch': 2.56}\n",
      "{'loss': 0.7044, 'grad_norm': 9.19837760925293, 'learning_rate': 6.3e-06, 'epoch': 2.58}\n",
      "{'loss': 0.8142, 'grad_norm': 7.7269110679626465, 'learning_rate': 6e-06, 'epoch': 2.6}\n",
      "{'loss': 0.6676, 'grad_norm': 6.887692928314209, 'learning_rate': 5.7000000000000005e-06, 'epoch': 2.62}\n",
      "{'loss': 0.6034, 'grad_norm': 3.2255494594573975, 'learning_rate': 5.4e-06, 'epoch': 2.64}\n",
      "{'loss': 0.6101, 'grad_norm': 9.29800796508789, 'learning_rate': 5.1e-06, 'epoch': 2.66}\n",
      "{'loss': 0.5807, 'grad_norm': 9.815712928771973, 'learning_rate': 4.800000000000001e-06, 'epoch': 2.68}\n",
      "{'loss': 0.5393, 'grad_norm': 5.699757099151611, 'learning_rate': 4.5e-06, 'epoch': 2.7}\n",
      "{'loss': 0.4735, 'grad_norm': 6.9143476486206055, 'learning_rate': 4.2000000000000004e-06, 'epoch': 2.72}\n",
      "{'loss': 0.6022, 'grad_norm': 8.82831859588623, 'learning_rate': 3.9e-06, 'epoch': 2.74}\n",
      "{'loss': 0.6365, 'grad_norm': 6.405145168304443, 'learning_rate': 3.6e-06, 'epoch': 2.76}\n",
      "{'loss': 0.5815, 'grad_norm': 13.747496604919434, 'learning_rate': 3.3e-06, 'epoch': 2.78}\n",
      "{'loss': 0.7875, 'grad_norm': 4.209402561187744, 'learning_rate': 3e-06, 'epoch': 2.8}\n",
      "{'loss': 0.658, 'grad_norm': 5.09108829498291, 'learning_rate': 2.7e-06, 'epoch': 2.82}\n",
      "{'loss': 0.6498, 'grad_norm': 4.51488733291626, 'learning_rate': 2.4000000000000003e-06, 'epoch': 2.84}\n",
      "{'loss': 0.7893, 'grad_norm': 9.907740592956543, 'learning_rate': 2.1000000000000002e-06, 'epoch': 2.86}\n",
      "{'loss': 0.4069, 'grad_norm': 3.239238739013672, 'learning_rate': 1.8e-06, 'epoch': 2.88}\n",
      "{'loss': 0.5737, 'grad_norm': 11.600517272949219, 'learning_rate': 1.5e-06, 'epoch': 2.9}\n",
      "{'loss': 0.6237, 'grad_norm': 8.560676574707031, 'learning_rate': 1.2000000000000002e-06, 'epoch': 2.92}\n",
      "{'loss': 0.6314, 'grad_norm': 5.743709087371826, 'learning_rate': 9e-07, 'epoch': 2.94}\n",
      "{'loss': 0.6633, 'grad_norm': 5.43712043762207, 'learning_rate': 6.000000000000001e-07, 'epoch': 2.96}\n",
      "{'loss': 0.5637, 'grad_norm': 7.085194110870361, 'learning_rate': 3.0000000000000004e-07, 'epoch': 2.98}\n",
      "{'loss': 0.7696, 'grad_norm': 9.649438858032227, 'learning_rate': 0.0, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "120be958da574e099d15ac8f57f8a3fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7682845592498779, 'eval_accuracy': 0.776, 'eval_runtime': 15.8192, 'eval_samples_per_second': 126.429, 'eval_steps_per_second': 2.023, 'epoch': 3.0}\n",
      "{'train_runtime': 756.4022, 'train_samples_per_second': 31.729, 'train_steps_per_second': 1.983, 'train_loss': 1.2076639874776205, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34014c862e41401c8df6b69fe0faa39c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Accuracy: 0.776\n",
      "Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml_final_project_env/lib/python3.8/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30a819f7e4f64b829a59c4c0bcf9848d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4855, 'grad_norm': 6.0171661376953125, 'learning_rate': 6.000000000000001e-07, 'epoch': 0.02}\n",
      "{'loss': 0.5653, 'grad_norm': 5.540102481842041, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.04}\n",
      "{'loss': 0.517, 'grad_norm': 5.162433624267578, 'learning_rate': 1.8e-06, 'epoch': 0.06}\n",
      "{'loss': 0.6352, 'grad_norm': 7.500098705291748, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.08}\n",
      "{'loss': 0.7359, 'grad_norm': 7.323812484741211, 'learning_rate': 3e-06, 'epoch': 0.1}\n",
      "{'loss': 0.58, 'grad_norm': 14.399991989135742, 'learning_rate': 3.6e-06, 'epoch': 0.12}\n",
      "{'loss': 0.621, 'grad_norm': 7.978931427001953, 'learning_rate': 4.2000000000000004e-06, 'epoch': 0.14}\n",
      "{'loss': 0.6629, 'grad_norm': 5.300823211669922, 'learning_rate': 4.800000000000001e-06, 'epoch': 0.16}\n",
      "{'loss': 0.7438, 'grad_norm': 7.815594673156738, 'learning_rate': 5.4e-06, 'epoch': 0.18}\n",
      "{'loss': 0.6141, 'grad_norm': 38.92424774169922, 'learning_rate': 6e-06, 'epoch': 0.2}\n",
      "{'loss': 0.6269, 'grad_norm': 11.418188095092773, 'learning_rate': 6.6e-06, 'epoch': 0.22}\n",
      "{'loss': 0.6516, 'grad_norm': 3.9429287910461426, 'learning_rate': 7.2e-06, 'epoch': 0.24}\n",
      "{'loss': 0.458, 'grad_norm': 11.0615873336792, 'learning_rate': 7.8e-06, 'epoch': 0.26}\n",
      "{'loss': 0.5888, 'grad_norm': 15.575847625732422, 'learning_rate': 8.400000000000001e-06, 'epoch': 0.28}\n",
      "{'loss': 0.6113, 'grad_norm': 8.967923164367676, 'learning_rate': 9e-06, 'epoch': 0.3}\n",
      "{'loss': 0.4539, 'grad_norm': 16.119140625, 'learning_rate': 9.600000000000001e-06, 'epoch': 0.32}\n",
      "{'loss': 0.6553, 'grad_norm': 11.048524856567383, 'learning_rate': 1.02e-05, 'epoch': 0.34}\n",
      "{'loss': 0.6717, 'grad_norm': 24.11625862121582, 'learning_rate': 1.08e-05, 'epoch': 0.36}\n",
      "{'loss': 0.701, 'grad_norm': 10.120113372802734, 'learning_rate': 1.1400000000000001e-05, 'epoch': 0.38}\n",
      "{'loss': 0.4864, 'grad_norm': 4.891471862792969, 'learning_rate': 1.2e-05, 'epoch': 0.4}\n",
      "{'loss': 0.4992, 'grad_norm': 5.435486316680908, 'learning_rate': 1.26e-05, 'epoch': 0.42}\n",
      "{'loss': 0.6148, 'grad_norm': 11.320676803588867, 'learning_rate': 1.32e-05, 'epoch': 0.44}\n",
      "{'loss': 0.5625, 'grad_norm': 14.340660095214844, 'learning_rate': 1.3800000000000002e-05, 'epoch': 0.46}\n",
      "{'loss': 0.5158, 'grad_norm': 7.863537788391113, 'learning_rate': 1.44e-05, 'epoch': 0.48}\n",
      "{'loss': 0.7255, 'grad_norm': 11.051824569702148, 'learning_rate': 1.5e-05, 'epoch': 0.5}\n",
      "{'loss': 0.7041, 'grad_norm': 5.521484375, 'learning_rate': 1.56e-05, 'epoch': 0.52}\n",
      "{'loss': 0.5283, 'grad_norm': 8.428949356079102, 'learning_rate': 1.62e-05, 'epoch': 0.54}\n",
      "{'loss': 0.8574, 'grad_norm': 5.480566501617432, 'learning_rate': 1.6800000000000002e-05, 'epoch': 0.56}\n",
      "{'loss': 0.7773, 'grad_norm': 6.888561248779297, 'learning_rate': 1.74e-05, 'epoch': 0.58}\n",
      "{'loss': 0.6473, 'grad_norm': 5.473687171936035, 'learning_rate': 1.8e-05, 'epoch': 0.6}\n",
      "{'loss': 0.5434, 'grad_norm': 3.271848678588867, 'learning_rate': 1.86e-05, 'epoch': 0.62}\n",
      "{'loss': 0.5433, 'grad_norm': 5.33883810043335, 'learning_rate': 1.9200000000000003e-05, 'epoch': 0.64}\n",
      "{'loss': 0.7388, 'grad_norm': 10.662124633789062, 'learning_rate': 1.98e-05, 'epoch': 0.66}\n",
      "{'loss': 0.643, 'grad_norm': 10.4417142868042, 'learning_rate': 2.04e-05, 'epoch': 0.68}\n",
      "{'loss': 0.5159, 'grad_norm': 2.1180953979492188, 'learning_rate': 2.1e-05, 'epoch': 0.7}\n",
      "{'loss': 0.6273, 'grad_norm': 6.508194923400879, 'learning_rate': 2.16e-05, 'epoch': 0.72}\n",
      "{'loss': 0.5845, 'grad_norm': 6.494552135467529, 'learning_rate': 2.22e-05, 'epoch': 0.74}\n",
      "{'loss': 0.5488, 'grad_norm': 5.983633995056152, 'learning_rate': 2.2800000000000002e-05, 'epoch': 0.76}\n",
      "{'loss': 0.5393, 'grad_norm': 3.159047842025757, 'learning_rate': 2.3400000000000003e-05, 'epoch': 0.78}\n",
      "{'loss': 0.7066, 'grad_norm': 6.175558090209961, 'learning_rate': 2.4e-05, 'epoch': 0.8}\n",
      "{'loss': 0.52, 'grad_norm': 11.484024047851562, 'learning_rate': 2.4599999999999998e-05, 'epoch': 0.82}\n",
      "{'loss': 0.5872, 'grad_norm': 11.717811584472656, 'learning_rate': 2.52e-05, 'epoch': 0.84}\n",
      "{'loss': 0.7198, 'grad_norm': 6.536375522613525, 'learning_rate': 2.58e-05, 'epoch': 0.86}\n",
      "{'loss': 0.6064, 'grad_norm': 5.88417387008667, 'learning_rate': 2.64e-05, 'epoch': 0.88}\n",
      "{'loss': 0.655, 'grad_norm': 5.150177478790283, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.9}\n",
      "{'loss': 0.5935, 'grad_norm': 21.2083797454834, 'learning_rate': 2.7600000000000003e-05, 'epoch': 0.92}\n",
      "{'loss': 0.6412, 'grad_norm': 7.187806129455566, 'learning_rate': 2.8199999999999998e-05, 'epoch': 0.94}\n",
      "{'loss': 0.6502, 'grad_norm': 15.712442398071289, 'learning_rate': 2.88e-05, 'epoch': 0.96}\n",
      "{'loss': 0.6603, 'grad_norm': 10.327825546264648, 'learning_rate': 2.94e-05, 'epoch': 0.98}\n",
      "{'loss': 0.5489, 'grad_norm': 7.009213447570801, 'learning_rate': 3e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f383028f0ce445686c49480cfedcbb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5647156834602356, 'eval_accuracy': 0.849, 'eval_runtime': 18.0847, 'eval_samples_per_second': 110.591, 'eval_steps_per_second': 1.769, 'epoch': 1.0}\n",
      "{'loss': 0.5656, 'grad_norm': 8.311917304992676, 'learning_rate': 2.97e-05, 'epoch': 1.02}\n",
      "{'loss': 0.4926, 'grad_norm': 6.132675647735596, 'learning_rate': 2.94e-05, 'epoch': 1.04}\n",
      "{'loss': 0.4884, 'grad_norm': 5.080969333648682, 'learning_rate': 2.91e-05, 'epoch': 1.06}\n",
      "{'loss': 0.545, 'grad_norm': 5.820079803466797, 'learning_rate': 2.88e-05, 'epoch': 1.08}\n",
      "{'loss': 0.4382, 'grad_norm': 7.559493064880371, 'learning_rate': 2.8499999999999998e-05, 'epoch': 1.1}\n",
      "{'loss': 0.5038, 'grad_norm': 11.68106746673584, 'learning_rate': 2.8199999999999998e-05, 'epoch': 1.12}\n",
      "{'loss': 0.7164, 'grad_norm': 7.071526050567627, 'learning_rate': 2.79e-05, 'epoch': 1.14}\n",
      "{'loss': 0.4905, 'grad_norm': 4.411729335784912, 'learning_rate': 2.7600000000000003e-05, 'epoch': 1.16}\n",
      "{'loss': 0.4444, 'grad_norm': 5.148263931274414, 'learning_rate': 2.7300000000000003e-05, 'epoch': 1.18}\n",
      "{'loss': 0.4218, 'grad_norm': 13.307692527770996, 'learning_rate': 2.7000000000000002e-05, 'epoch': 1.2}\n",
      "{'loss': 0.5698, 'grad_norm': 15.339546203613281, 'learning_rate': 2.6700000000000002e-05, 'epoch': 1.22}\n",
      "{'loss': 0.561, 'grad_norm': 6.265096664428711, 'learning_rate': 2.64e-05, 'epoch': 1.24}\n",
      "{'loss': 0.6224, 'grad_norm': 4.1057538986206055, 'learning_rate': 2.61e-05, 'epoch': 1.26}\n",
      "{'loss': 0.5669, 'grad_norm': 10.803020477294922, 'learning_rate': 2.58e-05, 'epoch': 1.28}\n",
      "{'loss': 0.3883, 'grad_norm': 22.977060317993164, 'learning_rate': 2.55e-05, 'epoch': 1.3}\n",
      "{'loss': 0.6171, 'grad_norm': 3.941378355026245, 'learning_rate': 2.52e-05, 'epoch': 1.32}\n",
      "{'loss': 0.4957, 'grad_norm': 7.929994106292725, 'learning_rate': 2.49e-05, 'epoch': 1.34}\n",
      "{'loss': 0.4663, 'grad_norm': 2.8897147178649902, 'learning_rate': 2.4599999999999998e-05, 'epoch': 1.36}\n",
      "{'loss': 0.5248, 'grad_norm': 6.32596492767334, 'learning_rate': 2.43e-05, 'epoch': 1.38}\n",
      "{'loss': 0.4948, 'grad_norm': 8.277488708496094, 'learning_rate': 2.4e-05, 'epoch': 1.4}\n",
      "{'loss': 0.571, 'grad_norm': 9.75818920135498, 'learning_rate': 2.37e-05, 'epoch': 1.42}\n",
      "{'loss': 0.4481, 'grad_norm': 5.477670669555664, 'learning_rate': 2.3400000000000003e-05, 'epoch': 1.44}\n",
      "{'loss': 0.3057, 'grad_norm': 7.61311149597168, 'learning_rate': 2.3100000000000002e-05, 'epoch': 1.46}\n",
      "{'loss': 0.3665, 'grad_norm': 11.180733680725098, 'learning_rate': 2.2800000000000002e-05, 'epoch': 1.48}\n",
      "{'loss': 0.4869, 'grad_norm': 23.18063735961914, 'learning_rate': 2.25e-05, 'epoch': 1.5}\n",
      "{'loss': 0.5204, 'grad_norm': 5.458895683288574, 'learning_rate': 2.22e-05, 'epoch': 1.52}\n",
      "{'loss': 0.4561, 'grad_norm': 4.615096569061279, 'learning_rate': 2.19e-05, 'epoch': 1.54}\n",
      "{'loss': 0.5717, 'grad_norm': 12.755593299865723, 'learning_rate': 2.16e-05, 'epoch': 1.56}\n",
      "{'loss': 0.5701, 'grad_norm': 3.4548451900482178, 'learning_rate': 2.13e-05, 'epoch': 1.58}\n",
      "{'loss': 0.4742, 'grad_norm': 4.076171875, 'learning_rate': 2.1e-05, 'epoch': 1.6}\n",
      "{'loss': 0.5491, 'grad_norm': 6.146043300628662, 'learning_rate': 2.07e-05, 'epoch': 1.62}\n",
      "{'loss': 0.4575, 'grad_norm': 9.219941139221191, 'learning_rate': 2.04e-05, 'epoch': 1.64}\n",
      "{'loss': 0.5715, 'grad_norm': 8.409568786621094, 'learning_rate': 2.01e-05, 'epoch': 1.66}\n",
      "{'loss': 0.3393, 'grad_norm': 5.277524471282959, 'learning_rate': 1.98e-05, 'epoch': 1.68}\n",
      "{'loss': 0.5904, 'grad_norm': 7.2911458015441895, 'learning_rate': 1.95e-05, 'epoch': 1.7}\n",
      "{'loss': 0.6095, 'grad_norm': 8.231812477111816, 'learning_rate': 1.9200000000000003e-05, 'epoch': 1.72}\n",
      "{'loss': 0.4421, 'grad_norm': 6.800980567932129, 'learning_rate': 1.8900000000000002e-05, 'epoch': 1.74}\n",
      "{'loss': 0.49, 'grad_norm': 16.797304153442383, 'learning_rate': 1.86e-05, 'epoch': 1.76}\n",
      "{'loss': 0.5673, 'grad_norm': 7.976321220397949, 'learning_rate': 1.83e-05, 'epoch': 1.78}\n",
      "{'loss': 0.3503, 'grad_norm': 3.869140863418579, 'learning_rate': 1.8e-05, 'epoch': 1.8}\n",
      "{'loss': 0.4301, 'grad_norm': 10.531086921691895, 'learning_rate': 1.77e-05, 'epoch': 1.82}\n",
      "{'loss': 0.5834, 'grad_norm': 5.023554801940918, 'learning_rate': 1.74e-05, 'epoch': 1.84}\n",
      "{'loss': 0.447, 'grad_norm': 5.135488510131836, 'learning_rate': 1.71e-05, 'epoch': 1.86}\n",
      "{'loss': 0.4675, 'grad_norm': 13.765154838562012, 'learning_rate': 1.6800000000000002e-05, 'epoch': 1.88}\n",
      "{'loss': 0.4569, 'grad_norm': 4.482110500335693, 'learning_rate': 1.65e-05, 'epoch': 1.9}\n",
      "{'loss': 0.4901, 'grad_norm': 12.147174835205078, 'learning_rate': 1.62e-05, 'epoch': 1.92}\n",
      "{'loss': 0.4903, 'grad_norm': 3.384688138961792, 'learning_rate': 1.59e-05, 'epoch': 1.94}\n",
      "{'loss': 0.4548, 'grad_norm': 6.238143444061279, 'learning_rate': 1.56e-05, 'epoch': 1.96}\n",
      "{'loss': 0.6974, 'grad_norm': 9.23989200592041, 'learning_rate': 1.53e-05, 'epoch': 1.98}\n",
      "{'loss': 0.6055, 'grad_norm': 11.244083404541016, 'learning_rate': 1.5e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26bac5d7e7b6461892269b91b64a502e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5549848675727844, 'eval_accuracy': 0.844, 'eval_runtime': 18.7995, 'eval_samples_per_second': 106.386, 'eval_steps_per_second': 1.702, 'epoch': 2.0}\n",
      "{'loss': 0.417, 'grad_norm': 4.750514030456543, 'learning_rate': 1.47e-05, 'epoch': 2.02}\n",
      "{'loss': 0.3059, 'grad_norm': 4.731209754943848, 'learning_rate': 1.44e-05, 'epoch': 2.04}\n",
      "{'loss': 0.3141, 'grad_norm': 7.226685523986816, 'learning_rate': 1.4099999999999999e-05, 'epoch': 2.06}\n",
      "{'loss': 0.3977, 'grad_norm': 3.6903207302093506, 'learning_rate': 1.3800000000000002e-05, 'epoch': 2.08}\n",
      "{'loss': 0.3038, 'grad_norm': 7.05663537979126, 'learning_rate': 1.3500000000000001e-05, 'epoch': 2.1}\n",
      "{'loss': 0.4182, 'grad_norm': 3.6349892616271973, 'learning_rate': 1.32e-05, 'epoch': 2.12}\n",
      "{'loss': 0.3198, 'grad_norm': 5.744533061981201, 'learning_rate': 1.29e-05, 'epoch': 2.14}\n",
      "{'loss': 0.4661, 'grad_norm': 4.190433025360107, 'learning_rate': 1.26e-05, 'epoch': 2.16}\n",
      "{'loss': 0.3224, 'grad_norm': 12.809032440185547, 'learning_rate': 1.2299999999999999e-05, 'epoch': 2.18}\n",
      "{'loss': 0.2735, 'grad_norm': 6.526361465454102, 'learning_rate': 1.2e-05, 'epoch': 2.2}\n",
      "{'loss': 0.3907, 'grad_norm': 9.081310272216797, 'learning_rate': 1.1700000000000001e-05, 'epoch': 2.22}\n",
      "{'loss': 0.3455, 'grad_norm': 6.514616966247559, 'learning_rate': 1.1400000000000001e-05, 'epoch': 2.24}\n",
      "{'loss': 0.1992, 'grad_norm': 6.03010892868042, 'learning_rate': 1.11e-05, 'epoch': 2.26}\n",
      "{'loss': 0.4246, 'grad_norm': 4.0765275955200195, 'learning_rate': 1.08e-05, 'epoch': 2.28}\n",
      "{'loss': 0.2368, 'grad_norm': 3.2315754890441895, 'learning_rate': 1.05e-05, 'epoch': 2.3}\n",
      "{'loss': 0.4147, 'grad_norm': 4.402002811431885, 'learning_rate': 1.02e-05, 'epoch': 2.32}\n",
      "{'loss': 0.3169, 'grad_norm': 3.389369249343872, 'learning_rate': 9.9e-06, 'epoch': 2.34}\n",
      "{'loss': 0.3519, 'grad_norm': 13.729259490966797, 'learning_rate': 9.600000000000001e-06, 'epoch': 2.36}\n",
      "{'loss': 0.2751, 'grad_norm': 6.405012130737305, 'learning_rate': 9.3e-06, 'epoch': 2.38}\n",
      "{'loss': 0.4062, 'grad_norm': 13.287993431091309, 'learning_rate': 9e-06, 'epoch': 2.4}\n",
      "{'loss': 0.2913, 'grad_norm': 6.158987045288086, 'learning_rate': 8.7e-06, 'epoch': 2.42}\n",
      "{'loss': 0.2069, 'grad_norm': 2.1734092235565186, 'learning_rate': 8.400000000000001e-06, 'epoch': 2.44}\n",
      "{'loss': 0.2077, 'grad_norm': 9.646414756774902, 'learning_rate': 8.1e-06, 'epoch': 2.46}\n",
      "{'loss': 0.2241, 'grad_norm': 4.696465492248535, 'learning_rate': 7.8e-06, 'epoch': 2.48}\n",
      "{'loss': 0.5046, 'grad_norm': 29.38251304626465, 'learning_rate': 7.5e-06, 'epoch': 2.5}\n",
      "{'loss': 0.2757, 'grad_norm': 2.014206886291504, 'learning_rate': 7.2e-06, 'epoch': 2.52}\n",
      "{'loss': 0.37, 'grad_norm': 6.294096946716309, 'learning_rate': 6.900000000000001e-06, 'epoch': 2.54}\n",
      "{'loss': 0.3037, 'grad_norm': 26.39914321899414, 'learning_rate': 6.6e-06, 'epoch': 2.56}\n",
      "{'loss': 0.3615, 'grad_norm': 5.8775200843811035, 'learning_rate': 6.3e-06, 'epoch': 2.58}\n",
      "{'loss': 0.3291, 'grad_norm': 2.090531826019287, 'learning_rate': 6e-06, 'epoch': 2.6}\n",
      "{'loss': 0.3228, 'grad_norm': 3.4986913204193115, 'learning_rate': 5.7000000000000005e-06, 'epoch': 2.62}\n",
      "{'loss': 0.3753, 'grad_norm': 12.244013786315918, 'learning_rate': 5.4e-06, 'epoch': 2.64}\n",
      "{'loss': 0.3348, 'grad_norm': 7.483278751373291, 'learning_rate': 5.1e-06, 'epoch': 2.66}\n",
      "{'loss': 0.2719, 'grad_norm': 5.768441677093506, 'learning_rate': 4.800000000000001e-06, 'epoch': 2.68}\n",
      "{'loss': 0.3643, 'grad_norm': 5.992212772369385, 'learning_rate': 4.5e-06, 'epoch': 2.7}\n",
      "{'loss': 0.2791, 'grad_norm': 2.8453989028930664, 'learning_rate': 4.2000000000000004e-06, 'epoch': 2.72}\n",
      "{'loss': 0.2934, 'grad_norm': 7.328016757965088, 'learning_rate': 3.9e-06, 'epoch': 2.74}\n",
      "{'loss': 0.4142, 'grad_norm': 7.244877338409424, 'learning_rate': 3.6e-06, 'epoch': 2.76}\n",
      "{'loss': 0.3588, 'grad_norm': 6.099181175231934, 'learning_rate': 3.3e-06, 'epoch': 2.78}\n",
      "{'loss': 0.4473, 'grad_norm': 8.407084465026855, 'learning_rate': 3e-06, 'epoch': 2.8}\n",
      "{'loss': 0.2604, 'grad_norm': 3.925995349884033, 'learning_rate': 2.7e-06, 'epoch': 2.82}\n",
      "{'loss': 0.3041, 'grad_norm': 3.4559130668640137, 'learning_rate': 2.4000000000000003e-06, 'epoch': 2.84}\n",
      "{'loss': 0.3631, 'grad_norm': 6.352916240692139, 'learning_rate': 2.1000000000000002e-06, 'epoch': 2.86}\n",
      "{'loss': 0.29, 'grad_norm': 8.10645580291748, 'learning_rate': 1.8e-06, 'epoch': 2.88}\n",
      "{'loss': 0.3939, 'grad_norm': 4.608395099639893, 'learning_rate': 1.5e-06, 'epoch': 2.9}\n",
      "{'loss': 0.3198, 'grad_norm': 11.577141761779785, 'learning_rate': 1.2000000000000002e-06, 'epoch': 2.92}\n",
      "{'loss': 0.3443, 'grad_norm': 8.391631126403809, 'learning_rate': 9e-07, 'epoch': 2.94}\n",
      "{'loss': 0.3295, 'grad_norm': 5.254039287567139, 'learning_rate': 6.000000000000001e-07, 'epoch': 2.96}\n",
      "{'loss': 0.2712, 'grad_norm': 2.0438289642333984, 'learning_rate': 3.0000000000000004e-07, 'epoch': 2.98}\n",
      "{'loss': 0.3886, 'grad_norm': 13.254155158996582, 'learning_rate': 0.0, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "410532253d8e42c39427fe1ba297039e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5185569524765015, 'eval_accuracy': 0.8485, 'eval_runtime': 22.0524, 'eval_samples_per_second': 90.693, 'eval_steps_per_second': 1.451, 'epoch': 3.0}\n",
      "{'train_runtime': 952.8283, 'train_samples_per_second': 25.188, 'train_steps_per_second': 1.574, 'train_loss': 0.48431474351882936, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b46616e6e084661851715afaab73a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Accuracy: 0.8485\n",
      "Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml_final_project_env/lib/python3.8/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9442348de39e4e48973734ef476cd02e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3251, 'grad_norm': 9.28596305847168, 'learning_rate': 6.000000000000001e-07, 'epoch': 0.02}\n",
      "{'loss': 0.316, 'grad_norm': 0.7765845060348511, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.04}\n",
      "{'loss': 0.3162, 'grad_norm': 5.880516052246094, 'learning_rate': 1.8e-06, 'epoch': 0.06}\n",
      "{'loss': 0.3017, 'grad_norm': 9.174625396728516, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.08}\n",
      "{'loss': 0.4094, 'grad_norm': 17.40515899658203, 'learning_rate': 3e-06, 'epoch': 0.1}\n",
      "{'loss': 0.3688, 'grad_norm': 3.4821841716766357, 'learning_rate': 3.6e-06, 'epoch': 0.12}\n",
      "{'loss': 0.3202, 'grad_norm': 6.980201721191406, 'learning_rate': 4.2000000000000004e-06, 'epoch': 0.14}\n",
      "{'loss': 0.2895, 'grad_norm': 1.6332606077194214, 'learning_rate': 4.800000000000001e-06, 'epoch': 0.16}\n",
      "{'loss': 0.3504, 'grad_norm': 13.925443649291992, 'learning_rate': 5.4e-06, 'epoch': 0.18}\n",
      "{'loss': 0.3797, 'grad_norm': 16.981630325317383, 'learning_rate': 6e-06, 'epoch': 0.2}\n",
      "{'loss': 0.3212, 'grad_norm': 7.286198616027832, 'learning_rate': 6.6e-06, 'epoch': 0.22}\n",
      "{'loss': 0.3236, 'grad_norm': 9.350329399108887, 'learning_rate': 7.2e-06, 'epoch': 0.24}\n",
      "{'loss': 0.323, 'grad_norm': 1.7488726377487183, 'learning_rate': 7.8e-06, 'epoch': 0.26}\n",
      "{'loss': 0.4075, 'grad_norm': 9.45823860168457, 'learning_rate': 8.400000000000001e-06, 'epoch': 0.28}\n",
      "{'loss': 0.3696, 'grad_norm': 8.477890968322754, 'learning_rate': 9e-06, 'epoch': 0.3}\n",
      "{'loss': 0.297, 'grad_norm': 6.643713474273682, 'learning_rate': 9.600000000000001e-06, 'epoch': 0.32}\n",
      "{'loss': 0.3713, 'grad_norm': 2.521979331970215, 'learning_rate': 1.02e-05, 'epoch': 0.34}\n",
      "{'loss': 0.3485, 'grad_norm': 6.230875492095947, 'learning_rate': 1.08e-05, 'epoch': 0.36}\n",
      "{'loss': 0.3312, 'grad_norm': 11.980122566223145, 'learning_rate': 1.1400000000000001e-05, 'epoch': 0.38}\n",
      "{'loss': 0.4939, 'grad_norm': 11.20124340057373, 'learning_rate': 1.2e-05, 'epoch': 0.4}\n",
      "{'loss': 0.2368, 'grad_norm': 7.405303478240967, 'learning_rate': 1.26e-05, 'epoch': 0.42}\n",
      "{'loss': 0.2884, 'grad_norm': 4.986584186553955, 'learning_rate': 1.32e-05, 'epoch': 0.44}\n",
      "{'loss': 0.3553, 'grad_norm': 7.5487284660339355, 'learning_rate': 1.3800000000000002e-05, 'epoch': 0.46}\n",
      "{'loss': 0.3292, 'grad_norm': 16.05499839782715, 'learning_rate': 1.44e-05, 'epoch': 0.48}\n",
      "{'loss': 0.4864, 'grad_norm': 8.889815330505371, 'learning_rate': 1.5e-05, 'epoch': 0.5}\n",
      "{'loss': 0.3988, 'grad_norm': 12.01356029510498, 'learning_rate': 1.56e-05, 'epoch': 0.52}\n",
      "{'loss': 0.5346, 'grad_norm': 10.263813972473145, 'learning_rate': 1.62e-05, 'epoch': 0.54}\n",
      "{'loss': 0.3347, 'grad_norm': 5.397444725036621, 'learning_rate': 1.6800000000000002e-05, 'epoch': 0.56}\n",
      "{'loss': 0.3582, 'grad_norm': 8.291298866271973, 'learning_rate': 1.74e-05, 'epoch': 0.58}\n",
      "{'loss': 0.3133, 'grad_norm': 2.2620859146118164, 'learning_rate': 1.8e-05, 'epoch': 0.6}\n",
      "{'loss': 0.4653, 'grad_norm': 7.999094486236572, 'learning_rate': 1.86e-05, 'epoch': 0.62}\n",
      "{'loss': 0.3296, 'grad_norm': 7.617980480194092, 'learning_rate': 1.9200000000000003e-05, 'epoch': 0.64}\n",
      "{'loss': 0.371, 'grad_norm': 5.249632835388184, 'learning_rate': 1.98e-05, 'epoch': 0.66}\n",
      "{'loss': 0.3698, 'grad_norm': 3.479062080383301, 'learning_rate': 2.04e-05, 'epoch': 0.68}\n",
      "{'loss': 0.3876, 'grad_norm': 0.5638747811317444, 'learning_rate': 2.1e-05, 'epoch': 0.7}\n",
      "{'loss': 0.3614, 'grad_norm': 10.104265213012695, 'learning_rate': 2.16e-05, 'epoch': 0.72}\n",
      "{'loss': 0.3678, 'grad_norm': 7.544040203094482, 'learning_rate': 2.22e-05, 'epoch': 0.74}\n",
      "{'loss': 0.3412, 'grad_norm': 14.193387985229492, 'learning_rate': 2.2800000000000002e-05, 'epoch': 0.76}\n",
      "{'loss': 0.2744, 'grad_norm': 4.185704708099365, 'learning_rate': 2.3400000000000003e-05, 'epoch': 0.78}\n",
      "{'loss': 0.5832, 'grad_norm': 10.416311264038086, 'learning_rate': 2.4e-05, 'epoch': 0.8}\n",
      "{'loss': 0.2925, 'grad_norm': 12.41761302947998, 'learning_rate': 2.4599999999999998e-05, 'epoch': 0.82}\n",
      "{'loss': 0.4501, 'grad_norm': 13.019423484802246, 'learning_rate': 2.52e-05, 'epoch': 0.84}\n",
      "{'loss': 0.4334, 'grad_norm': 16.41559600830078, 'learning_rate': 2.58e-05, 'epoch': 0.86}\n",
      "{'loss': 0.3869, 'grad_norm': 7.9922637939453125, 'learning_rate': 2.64e-05, 'epoch': 0.88}\n",
      "{'loss': 0.3141, 'grad_norm': 4.609509468078613, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.9}\n",
      "{'loss': 0.3781, 'grad_norm': 13.960846900939941, 'learning_rate': 2.7600000000000003e-05, 'epoch': 0.92}\n",
      "{'loss': 0.38, 'grad_norm': 4.454726219177246, 'learning_rate': 2.8199999999999998e-05, 'epoch': 0.94}\n",
      "{'loss': 0.4581, 'grad_norm': 5.809962749481201, 'learning_rate': 2.88e-05, 'epoch': 0.96}\n",
      "{'loss': 0.4277, 'grad_norm': 12.039770126342773, 'learning_rate': 2.94e-05, 'epoch': 0.98}\n",
      "{'loss': 0.4587, 'grad_norm': 19.322559356689453, 'learning_rate': 3e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a132da7d6664d42ac3fb426a38c0869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.27562668919563293, 'eval_accuracy': 0.9155, 'eval_runtime': 21.9253, 'eval_samples_per_second': 91.219, 'eval_steps_per_second': 1.46, 'epoch': 1.0}\n",
      "{'loss': 0.3284, 'grad_norm': 10.213953018188477, 'learning_rate': 2.97e-05, 'epoch': 1.02}\n",
      "{'loss': 0.2829, 'grad_norm': 24.42681121826172, 'learning_rate': 2.94e-05, 'epoch': 1.04}\n",
      "{'loss': 0.3017, 'grad_norm': 2.754493236541748, 'learning_rate': 2.91e-05, 'epoch': 1.06}\n",
      "{'loss': 0.197, 'grad_norm': 1.3194053173065186, 'learning_rate': 2.88e-05, 'epoch': 1.08}\n",
      "{'loss': 0.2285, 'grad_norm': 8.468499183654785, 'learning_rate': 2.8499999999999998e-05, 'epoch': 1.1}\n",
      "{'loss': 0.2765, 'grad_norm': 17.018878936767578, 'learning_rate': 2.8199999999999998e-05, 'epoch': 1.12}\n",
      "{'loss': 0.3535, 'grad_norm': 12.872771263122559, 'learning_rate': 2.79e-05, 'epoch': 1.14}\n",
      "{'loss': 0.3313, 'grad_norm': 6.430898666381836, 'learning_rate': 2.7600000000000003e-05, 'epoch': 1.16}\n",
      "{'loss': 0.2772, 'grad_norm': 6.542217254638672, 'learning_rate': 2.7300000000000003e-05, 'epoch': 1.18}\n",
      "{'loss': 0.3652, 'grad_norm': 5.9461989402771, 'learning_rate': 2.7000000000000002e-05, 'epoch': 1.2}\n",
      "{'loss': 0.331, 'grad_norm': 5.743712425231934, 'learning_rate': 2.6700000000000002e-05, 'epoch': 1.22}\n",
      "{'loss': 0.2595, 'grad_norm': 5.62868070602417, 'learning_rate': 2.64e-05, 'epoch': 1.24}\n",
      "{'loss': 0.3766, 'grad_norm': 49.49848175048828, 'learning_rate': 2.61e-05, 'epoch': 1.26}\n",
      "{'loss': 0.37, 'grad_norm': 7.947351932525635, 'learning_rate': 2.58e-05, 'epoch': 1.28}\n",
      "{'loss': 0.2713, 'grad_norm': 11.76285171508789, 'learning_rate': 2.55e-05, 'epoch': 1.3}\n",
      "{'loss': 0.4019, 'grad_norm': 8.219625473022461, 'learning_rate': 2.52e-05, 'epoch': 1.32}\n",
      "{'loss': 0.15, 'grad_norm': 3.208554267883301, 'learning_rate': 2.49e-05, 'epoch': 1.34}\n",
      "{'loss': 0.3967, 'grad_norm': 4.951098442077637, 'learning_rate': 2.4599999999999998e-05, 'epoch': 1.36}\n",
      "{'loss': 0.3567, 'grad_norm': 7.728470802307129, 'learning_rate': 2.43e-05, 'epoch': 1.38}\n",
      "{'loss': 0.2349, 'grad_norm': 6.694287300109863, 'learning_rate': 2.4e-05, 'epoch': 1.4}\n",
      "{'loss': 0.2866, 'grad_norm': 4.243019104003906, 'learning_rate': 2.37e-05, 'epoch': 1.42}\n",
      "{'loss': 0.317, 'grad_norm': 21.99485206604004, 'learning_rate': 2.3400000000000003e-05, 'epoch': 1.44}\n",
      "{'loss': 0.3102, 'grad_norm': 9.970507621765137, 'learning_rate': 2.3100000000000002e-05, 'epoch': 1.46}\n",
      "{'loss': 0.4173, 'grad_norm': 11.995682716369629, 'learning_rate': 2.2800000000000002e-05, 'epoch': 1.48}\n",
      "{'loss': 0.2837, 'grad_norm': 15.406280517578125, 'learning_rate': 2.25e-05, 'epoch': 1.5}\n",
      "{'loss': 0.2786, 'grad_norm': 12.21085262298584, 'learning_rate': 2.22e-05, 'epoch': 1.52}\n",
      "{'loss': 0.3774, 'grad_norm': 6.906949996948242, 'learning_rate': 2.19e-05, 'epoch': 1.54}\n",
      "{'loss': 0.3377, 'grad_norm': 5.342031955718994, 'learning_rate': 2.16e-05, 'epoch': 1.56}\n",
      "{'loss': 0.5153, 'grad_norm': 2.9430036544799805, 'learning_rate': 2.13e-05, 'epoch': 1.58}\n",
      "{'loss': 0.3223, 'grad_norm': 7.086926460266113, 'learning_rate': 2.1e-05, 'epoch': 1.6}\n",
      "{'loss': 0.2386, 'grad_norm': 9.571730613708496, 'learning_rate': 2.07e-05, 'epoch': 1.62}\n",
      "{'loss': 0.3118, 'grad_norm': 4.2902374267578125, 'learning_rate': 2.04e-05, 'epoch': 1.64}\n",
      "{'loss': 0.237, 'grad_norm': 3.9337596893310547, 'learning_rate': 2.01e-05, 'epoch': 1.66}\n",
      "{'loss': 0.2278, 'grad_norm': 14.263262748718262, 'learning_rate': 1.98e-05, 'epoch': 1.68}\n",
      "{'loss': 0.4053, 'grad_norm': 20.566852569580078, 'learning_rate': 1.95e-05, 'epoch': 1.7}\n",
      "{'loss': 0.3745, 'grad_norm': 12.855332374572754, 'learning_rate': 1.9200000000000003e-05, 'epoch': 1.72}\n",
      "{'loss': 0.1923, 'grad_norm': 12.901775360107422, 'learning_rate': 1.8900000000000002e-05, 'epoch': 1.74}\n",
      "{'loss': 0.1992, 'grad_norm': 0.3229730427265167, 'learning_rate': 1.86e-05, 'epoch': 1.76}\n",
      "{'loss': 0.4179, 'grad_norm': 12.3629150390625, 'learning_rate': 1.83e-05, 'epoch': 1.78}\n",
      "{'loss': 0.1775, 'grad_norm': 7.112824440002441, 'learning_rate': 1.8e-05, 'epoch': 1.8}\n",
      "{'loss': 0.2665, 'grad_norm': 8.216946601867676, 'learning_rate': 1.77e-05, 'epoch': 1.82}\n",
      "{'loss': 0.4175, 'grad_norm': 7.3521647453308105, 'learning_rate': 1.74e-05, 'epoch': 1.84}\n",
      "{'loss': 0.3424, 'grad_norm': 6.184078693389893, 'learning_rate': 1.71e-05, 'epoch': 1.86}\n",
      "{'loss': 0.3936, 'grad_norm': 6.003538131713867, 'learning_rate': 1.6800000000000002e-05, 'epoch': 1.88}\n",
      "{'loss': 0.4038, 'grad_norm': 11.939850807189941, 'learning_rate': 1.65e-05, 'epoch': 1.9}\n",
      "{'loss': 0.4113, 'grad_norm': 4.469510555267334, 'learning_rate': 1.62e-05, 'epoch': 1.92}\n",
      "{'loss': 0.2095, 'grad_norm': 3.342099189758301, 'learning_rate': 1.59e-05, 'epoch': 1.94}\n",
      "{'loss': 0.3965, 'grad_norm': 8.696125030517578, 'learning_rate': 1.56e-05, 'epoch': 1.96}\n",
      "{'loss': 0.4344, 'grad_norm': 5.157207012176514, 'learning_rate': 1.53e-05, 'epoch': 1.98}\n",
      "{'loss': 0.4491, 'grad_norm': 11.177674293518066, 'learning_rate': 1.5e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c9ffc23d100464b9131cec928ca53fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2606903612613678, 'eval_accuracy': 0.9225, 'eval_runtime': 22.7566, 'eval_samples_per_second': 87.887, 'eval_steps_per_second': 1.406, 'epoch': 2.0}\n",
      "{'loss': 0.1214, 'grad_norm': 12.350945472717285, 'learning_rate': 1.47e-05, 'epoch': 2.02}\n",
      "{'loss': 0.2106, 'grad_norm': 8.887292861938477, 'learning_rate': 1.44e-05, 'epoch': 2.04}\n",
      "{'loss': 0.1765, 'grad_norm': 6.2453389167785645, 'learning_rate': 1.4099999999999999e-05, 'epoch': 2.06}\n",
      "{'loss': 0.2228, 'grad_norm': 2.9435460567474365, 'learning_rate': 1.3800000000000002e-05, 'epoch': 2.08}\n",
      "{'loss': 0.1819, 'grad_norm': 15.806419372558594, 'learning_rate': 1.3500000000000001e-05, 'epoch': 2.1}\n",
      "{'loss': 0.371, 'grad_norm': 1.9692575931549072, 'learning_rate': 1.32e-05, 'epoch': 2.12}\n",
      "{'loss': 0.1969, 'grad_norm': 2.5946662425994873, 'learning_rate': 1.29e-05, 'epoch': 2.14}\n",
      "{'loss': 0.2467, 'grad_norm': 9.44793701171875, 'learning_rate': 1.26e-05, 'epoch': 2.16}\n",
      "{'loss': 0.2201, 'grad_norm': 3.5941600799560547, 'learning_rate': 1.2299999999999999e-05, 'epoch': 2.18}\n",
      "{'loss': 0.1552, 'grad_norm': 0.5979399681091309, 'learning_rate': 1.2e-05, 'epoch': 2.2}\n",
      "{'loss': 0.2122, 'grad_norm': 3.9078056812286377, 'learning_rate': 1.1700000000000001e-05, 'epoch': 2.22}\n",
      "{'loss': 0.1414, 'grad_norm': 10.252471923828125, 'learning_rate': 1.1400000000000001e-05, 'epoch': 2.24}\n",
      "{'loss': 0.0836, 'grad_norm': 1.0066829919815063, 'learning_rate': 1.11e-05, 'epoch': 2.26}\n",
      "{'loss': 0.2476, 'grad_norm': 15.720781326293945, 'learning_rate': 1.08e-05, 'epoch': 2.28}\n",
      "{'loss': 0.2271, 'grad_norm': 8.154687881469727, 'learning_rate': 1.05e-05, 'epoch': 2.3}\n",
      "{'loss': 0.2118, 'grad_norm': 5.059203624725342, 'learning_rate': 1.02e-05, 'epoch': 2.32}\n",
      "{'loss': 0.0762, 'grad_norm': 8.09351634979248, 'learning_rate': 9.9e-06, 'epoch': 2.34}\n",
      "{'loss': 0.2713, 'grad_norm': 60.75845718383789, 'learning_rate': 9.600000000000001e-06, 'epoch': 2.36}\n",
      "{'loss': 0.1601, 'grad_norm': 4.020197868347168, 'learning_rate': 9.3e-06, 'epoch': 2.38}\n",
      "{'loss': 0.1562, 'grad_norm': 1.308516025543213, 'learning_rate': 9e-06, 'epoch': 2.4}\n",
      "{'loss': 0.2559, 'grad_norm': 10.481821060180664, 'learning_rate': 8.7e-06, 'epoch': 2.42}\n",
      "{'loss': 0.1512, 'grad_norm': 5.50600528717041, 'learning_rate': 8.400000000000001e-06, 'epoch': 2.44}\n",
      "{'loss': 0.1204, 'grad_norm': 4.221714019775391, 'learning_rate': 8.1e-06, 'epoch': 2.46}\n",
      "{'loss': 0.1189, 'grad_norm': 0.27700144052505493, 'learning_rate': 7.8e-06, 'epoch': 2.48}\n",
      "{'loss': 0.2194, 'grad_norm': 8.034327507019043, 'learning_rate': 7.5e-06, 'epoch': 2.5}\n",
      "{'loss': 0.1523, 'grad_norm': 4.4847211837768555, 'learning_rate': 7.2e-06, 'epoch': 2.52}\n",
      "{'loss': 0.2444, 'grad_norm': 5.982374668121338, 'learning_rate': 6.900000000000001e-06, 'epoch': 2.54}\n",
      "{'loss': 0.21, 'grad_norm': 4.146017074584961, 'learning_rate': 6.6e-06, 'epoch': 2.56}\n",
      "{'loss': 0.1651, 'grad_norm': 27.959333419799805, 'learning_rate': 6.3e-06, 'epoch': 2.58}\n",
      "{'loss': 0.2199, 'grad_norm': 13.63633918762207, 'learning_rate': 6e-06, 'epoch': 2.6}\n",
      "{'loss': 0.2554, 'grad_norm': 0.31585463881492615, 'learning_rate': 5.7000000000000005e-06, 'epoch': 2.62}\n",
      "{'loss': 0.2674, 'grad_norm': 6.374691009521484, 'learning_rate': 5.4e-06, 'epoch': 2.64}\n",
      "{'loss': 0.1359, 'grad_norm': 3.705502986907959, 'learning_rate': 5.1e-06, 'epoch': 2.66}\n",
      "{'loss': 0.1724, 'grad_norm': 5.245705604553223, 'learning_rate': 4.800000000000001e-06, 'epoch': 2.68}\n",
      "{'loss': 0.157, 'grad_norm': 42.33729934692383, 'learning_rate': 4.5e-06, 'epoch': 2.7}\n",
      "{'loss': 0.1702, 'grad_norm': 0.33813172578811646, 'learning_rate': 4.2000000000000004e-06, 'epoch': 2.72}\n",
      "{'loss': 0.1171, 'grad_norm': 7.359421730041504, 'learning_rate': 3.9e-06, 'epoch': 2.74}\n",
      "{'loss': 0.1833, 'grad_norm': 3.7714736461639404, 'learning_rate': 3.6e-06, 'epoch': 2.76}\n",
      "{'loss': 0.24, 'grad_norm': 6.902039051055908, 'learning_rate': 3.3e-06, 'epoch': 2.78}\n",
      "{'loss': 0.1794, 'grad_norm': 11.894818305969238, 'learning_rate': 3e-06, 'epoch': 2.8}\n",
      "{'loss': 0.1843, 'grad_norm': 12.107551574707031, 'learning_rate': 2.7e-06, 'epoch': 2.82}\n",
      "{'loss': 0.1769, 'grad_norm': 1.0603774785995483, 'learning_rate': 2.4000000000000003e-06, 'epoch': 2.84}\n",
      "{'loss': 0.2178, 'grad_norm': 4.71429967880249, 'learning_rate': 2.1000000000000002e-06, 'epoch': 2.86}\n",
      "{'loss': 0.2094, 'grad_norm': 9.413028717041016, 'learning_rate': 1.8e-06, 'epoch': 2.88}\n",
      "{'loss': 0.1453, 'grad_norm': 5.006550312042236, 'learning_rate': 1.5e-06, 'epoch': 2.9}\n",
      "{'loss': 0.1564, 'grad_norm': 0.45444974303245544, 'learning_rate': 1.2000000000000002e-06, 'epoch': 2.92}\n",
      "{'loss': 0.135, 'grad_norm': 3.701935291290283, 'learning_rate': 9e-07, 'epoch': 2.94}\n",
      "{'loss': 0.1194, 'grad_norm': 8.037134170532227, 'learning_rate': 6.000000000000001e-07, 'epoch': 2.96}\n",
      "{'loss': 0.1371, 'grad_norm': 4.346839427947998, 'learning_rate': 3.0000000000000004e-07, 'epoch': 2.98}\n",
      "{'loss': 0.2603, 'grad_norm': 4.812477111816406, 'learning_rate': 0.0, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0933c3f923a4140abc36ca0ea662d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.23848211765289307, 'eval_accuracy': 0.9305, 'eval_runtime': 22.7247, 'eval_samples_per_second': 88.01, 'eval_steps_per_second': 1.408, 'epoch': 3.0}\n",
      "{'train_runtime': 1025.4144, 'train_samples_per_second': 23.405, 'train_steps_per_second': 1.463, 'train_loss': 0.29227965605258943, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "541b7341d0264c06b851ec9784388296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Accuracy: 0.9305\n",
      "Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml_final_project_env/lib/python3.8/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "198139bdfbb24fd09e1238a4e18af144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1615, 'grad_norm': 13.674853324890137, 'learning_rate': 6.000000000000001e-07, 'epoch': 0.02}\n",
      "{'loss': 0.1792, 'grad_norm': 3.3164141178131104, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.04}\n",
      "{'loss': 0.1414, 'grad_norm': 5.857432842254639, 'learning_rate': 1.8e-06, 'epoch': 0.06}\n",
      "{'loss': 0.2294, 'grad_norm': 4.3923726081848145, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.08}\n",
      "{'loss': 0.2642, 'grad_norm': 3.4305381774902344, 'learning_rate': 3e-06, 'epoch': 0.1}\n",
      "{'loss': 0.1177, 'grad_norm': 4.379964351654053, 'learning_rate': 3.6e-06, 'epoch': 0.12}\n",
      "{'loss': 0.1206, 'grad_norm': 3.7059805393218994, 'learning_rate': 4.2000000000000004e-06, 'epoch': 0.14}\n",
      "{'loss': 0.2507, 'grad_norm': 7.7701921463012695, 'learning_rate': 4.800000000000001e-06, 'epoch': 0.16}\n",
      "{'loss': 0.1691, 'grad_norm': 6.404401779174805, 'learning_rate': 5.4e-06, 'epoch': 0.18}\n",
      "{'loss': 0.1752, 'grad_norm': 13.235957145690918, 'learning_rate': 6e-06, 'epoch': 0.2}\n",
      "{'loss': 0.1274, 'grad_norm': 7.403993129730225, 'learning_rate': 6.6e-06, 'epoch': 0.22}\n",
      "{'loss': 0.2466, 'grad_norm': 16.906492233276367, 'learning_rate': 7.2e-06, 'epoch': 0.24}\n",
      "{'loss': 0.1755, 'grad_norm': 0.40639063715934753, 'learning_rate': 7.8e-06, 'epoch': 0.26}\n",
      "{'loss': 0.129, 'grad_norm': 8.549358367919922, 'learning_rate': 8.400000000000001e-06, 'epoch': 0.28}\n",
      "{'loss': 0.2051, 'grad_norm': 0.2814617455005646, 'learning_rate': 9e-06, 'epoch': 0.3}\n",
      "{'loss': 0.2469, 'grad_norm': 2.322122573852539, 'learning_rate': 9.600000000000001e-06, 'epoch': 0.32}\n",
      "{'loss': 0.1783, 'grad_norm': 15.178218841552734, 'learning_rate': 1.02e-05, 'epoch': 0.34}\n",
      "{'loss': 0.1676, 'grad_norm': 0.26786690950393677, 'learning_rate': 1.08e-05, 'epoch': 0.36}\n",
      "{'loss': 0.0733, 'grad_norm': 3.0113089084625244, 'learning_rate': 1.1400000000000001e-05, 'epoch': 0.38}\n",
      "{'loss': 0.2587, 'grad_norm': 13.446797370910645, 'learning_rate': 1.2e-05, 'epoch': 0.4}\n",
      "{'loss': 0.1066, 'grad_norm': 16.299591064453125, 'learning_rate': 1.26e-05, 'epoch': 0.42}\n",
      "{'loss': 0.2662, 'grad_norm': 1.159575343132019, 'learning_rate': 1.32e-05, 'epoch': 0.44}\n",
      "{'loss': 0.1217, 'grad_norm': 12.76321029663086, 'learning_rate': 1.3800000000000002e-05, 'epoch': 0.46}\n",
      "{'loss': 0.2372, 'grad_norm': 14.780600547790527, 'learning_rate': 1.44e-05, 'epoch': 0.48}\n",
      "{'loss': 0.2444, 'grad_norm': 19.39897918701172, 'learning_rate': 1.5e-05, 'epoch': 0.5}\n",
      "{'loss': 0.1879, 'grad_norm': 3.9930646419525146, 'learning_rate': 1.56e-05, 'epoch': 0.52}\n",
      "{'loss': 0.2069, 'grad_norm': 4.872703552246094, 'learning_rate': 1.62e-05, 'epoch': 0.54}\n",
      "{'loss': 0.0922, 'grad_norm': 6.0100932121276855, 'learning_rate': 1.6800000000000002e-05, 'epoch': 0.56}\n",
      "{'loss': 0.1858, 'grad_norm': 12.300914764404297, 'learning_rate': 1.74e-05, 'epoch': 0.58}\n",
      "{'loss': 0.2057, 'grad_norm': 0.5075122714042664, 'learning_rate': 1.8e-05, 'epoch': 0.6}\n",
      "{'loss': 0.1719, 'grad_norm': 9.29155158996582, 'learning_rate': 1.86e-05, 'epoch': 0.62}\n",
      "{'loss': 0.1472, 'grad_norm': 1.8949782848358154, 'learning_rate': 1.9200000000000003e-05, 'epoch': 0.64}\n",
      "{'loss': 0.2091, 'grad_norm': 7.053997039794922, 'learning_rate': 1.98e-05, 'epoch': 0.66}\n",
      "{'loss': 0.1721, 'grad_norm': 5.1584858894348145, 'learning_rate': 2.04e-05, 'epoch': 0.68}\n",
      "{'loss': 0.0971, 'grad_norm': 5.865307331085205, 'learning_rate': 2.1e-05, 'epoch': 0.7}\n",
      "{'loss': 0.3019, 'grad_norm': 3.81630539894104, 'learning_rate': 2.16e-05, 'epoch': 0.72}\n",
      "{'loss': 0.3676, 'grad_norm': 8.110891342163086, 'learning_rate': 2.22e-05, 'epoch': 0.74}\n",
      "{'loss': 0.2166, 'grad_norm': 8.914368629455566, 'learning_rate': 2.2800000000000002e-05, 'epoch': 0.76}\n",
      "{'loss': 0.2667, 'grad_norm': 17.221771240234375, 'learning_rate': 2.3400000000000003e-05, 'epoch': 0.78}\n",
      "{'loss': 0.2612, 'grad_norm': 2.1591198444366455, 'learning_rate': 2.4e-05, 'epoch': 0.8}\n",
      "{'loss': 0.1737, 'grad_norm': 6.355173587799072, 'learning_rate': 2.4599999999999998e-05, 'epoch': 0.82}\n",
      "{'loss': 0.1588, 'grad_norm': 7.425036430358887, 'learning_rate': 2.52e-05, 'epoch': 0.84}\n",
      "{'loss': 0.2018, 'grad_norm': 1.9369888305664062, 'learning_rate': 2.58e-05, 'epoch': 0.86}\n",
      "{'loss': 0.1958, 'grad_norm': 8.506280899047852, 'learning_rate': 2.64e-05, 'epoch': 0.88}\n",
      "{'loss': 0.1736, 'grad_norm': 2.8043034076690674, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.9}\n",
      "{'loss': 0.3516, 'grad_norm': 21.365341186523438, 'learning_rate': 2.7600000000000003e-05, 'epoch': 0.92}\n",
      "{'loss': 0.2552, 'grad_norm': 0.4248693883419037, 'learning_rate': 2.8199999999999998e-05, 'epoch': 0.94}\n",
      "{'loss': 0.2548, 'grad_norm': 14.412375450134277, 'learning_rate': 2.88e-05, 'epoch': 0.96}\n",
      "{'loss': 0.1895, 'grad_norm': 1.3067057132720947, 'learning_rate': 2.94e-05, 'epoch': 0.98}\n",
      "{'loss': 0.2504, 'grad_norm': 3.078620433807373, 'learning_rate': 3e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc4da2900064a6ca9789daa6e738719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1420496255159378, 'eval_accuracy': 0.961, 'eval_runtime': 20.5813, 'eval_samples_per_second': 97.176, 'eval_steps_per_second': 1.555, 'epoch': 1.0}\n",
      "{'loss': 0.1682, 'grad_norm': 1.1590909957885742, 'learning_rate': 2.97e-05, 'epoch': 1.02}\n",
      "{'loss': 0.1957, 'grad_norm': 10.220529556274414, 'learning_rate': 2.94e-05, 'epoch': 1.04}\n",
      "{'loss': 0.0928, 'grad_norm': 1.3845564126968384, 'learning_rate': 2.91e-05, 'epoch': 1.06}\n",
      "{'loss': 0.2126, 'grad_norm': 5.288599491119385, 'learning_rate': 2.88e-05, 'epoch': 1.08}\n",
      "{'loss': 0.1277, 'grad_norm': 2.4929325580596924, 'learning_rate': 2.8499999999999998e-05, 'epoch': 1.1}\n",
      "{'loss': 0.0969, 'grad_norm': 1.9464986324310303, 'learning_rate': 2.8199999999999998e-05, 'epoch': 1.12}\n",
      "{'loss': 0.1477, 'grad_norm': 0.8946974873542786, 'learning_rate': 2.79e-05, 'epoch': 1.14}\n",
      "{'loss': 0.1802, 'grad_norm': 9.115854263305664, 'learning_rate': 2.7600000000000003e-05, 'epoch': 1.16}\n",
      "{'loss': 0.1147, 'grad_norm': 5.617850303649902, 'learning_rate': 2.7300000000000003e-05, 'epoch': 1.18}\n",
      "{'loss': 0.1334, 'grad_norm': 0.582017719745636, 'learning_rate': 2.7000000000000002e-05, 'epoch': 1.2}\n",
      "{'loss': 0.2057, 'grad_norm': 3.0447070598602295, 'learning_rate': 2.6700000000000002e-05, 'epoch': 1.22}\n",
      "{'loss': 0.2402, 'grad_norm': 5.89590311050415, 'learning_rate': 2.64e-05, 'epoch': 1.24}\n",
      "{'loss': 0.1194, 'grad_norm': 3.2916629314422607, 'learning_rate': 2.61e-05, 'epoch': 1.26}\n",
      "{'loss': 0.1817, 'grad_norm': 15.150893211364746, 'learning_rate': 2.58e-05, 'epoch': 1.28}\n",
      "{'loss': 0.2416, 'grad_norm': 10.73929500579834, 'learning_rate': 2.55e-05, 'epoch': 1.3}\n",
      "{'loss': 0.1921, 'grad_norm': 16.992496490478516, 'learning_rate': 2.52e-05, 'epoch': 1.32}\n",
      "{'loss': 0.1239, 'grad_norm': 22.22085189819336, 'learning_rate': 2.49e-05, 'epoch': 1.34}\n",
      "{'loss': 0.1021, 'grad_norm': 5.6757636070251465, 'learning_rate': 2.4599999999999998e-05, 'epoch': 1.36}\n",
      "{'loss': 0.186, 'grad_norm': 18.23430824279785, 'learning_rate': 2.43e-05, 'epoch': 1.38}\n",
      "{'loss': 0.1444, 'grad_norm': 5.064347267150879, 'learning_rate': 2.4e-05, 'epoch': 1.4}\n",
      "{'loss': 0.1571, 'grad_norm': 8.102606773376465, 'learning_rate': 2.37e-05, 'epoch': 1.42}\n",
      "{'loss': 0.1574, 'grad_norm': 0.12643201649188995, 'learning_rate': 2.3400000000000003e-05, 'epoch': 1.44}\n",
      "{'loss': 0.1893, 'grad_norm': 0.6847500205039978, 'learning_rate': 2.3100000000000002e-05, 'epoch': 1.46}\n",
      "{'loss': 0.1331, 'grad_norm': 6.723827838897705, 'learning_rate': 2.2800000000000002e-05, 'epoch': 1.48}\n",
      "{'loss': 0.1269, 'grad_norm': 2.884836435317993, 'learning_rate': 2.25e-05, 'epoch': 1.5}\n",
      "{'loss': 0.1626, 'grad_norm': 15.805728912353516, 'learning_rate': 2.22e-05, 'epoch': 1.52}\n",
      "{'loss': 0.1928, 'grad_norm': 0.6723544001579285, 'learning_rate': 2.19e-05, 'epoch': 1.54}\n",
      "{'loss': 0.2714, 'grad_norm': 46.83173370361328, 'learning_rate': 2.16e-05, 'epoch': 1.56}\n",
      "{'loss': 0.2538, 'grad_norm': 19.274913787841797, 'learning_rate': 2.13e-05, 'epoch': 1.58}\n",
      "{'loss': 0.1719, 'grad_norm': 6.8349833488464355, 'learning_rate': 2.1e-05, 'epoch': 1.6}\n",
      "{'loss': 0.177, 'grad_norm': 8.159131050109863, 'learning_rate': 2.07e-05, 'epoch': 1.62}\n",
      "{'loss': 0.237, 'grad_norm': 9.686592102050781, 'learning_rate': 2.04e-05, 'epoch': 1.64}\n",
      "{'loss': 0.1064, 'grad_norm': 1.392673134803772, 'learning_rate': 2.01e-05, 'epoch': 1.66}\n",
      "{'loss': 0.1983, 'grad_norm': 8.586181640625, 'learning_rate': 1.98e-05, 'epoch': 1.68}\n",
      "{'loss': 0.2788, 'grad_norm': 10.01632022857666, 'learning_rate': 1.95e-05, 'epoch': 1.7}\n",
      "{'loss': 0.2932, 'grad_norm': 8.842301368713379, 'learning_rate': 1.9200000000000003e-05, 'epoch': 1.72}\n",
      "{'loss': 0.2514, 'grad_norm': 8.4772367477417, 'learning_rate': 1.8900000000000002e-05, 'epoch': 1.74}\n",
      "{'loss': 0.2221, 'grad_norm': 1.5183191299438477, 'learning_rate': 1.86e-05, 'epoch': 1.76}\n",
      "{'loss': 0.1322, 'grad_norm': 3.629112958908081, 'learning_rate': 1.83e-05, 'epoch': 1.78}\n",
      "{'loss': 0.1261, 'grad_norm': 11.629297256469727, 'learning_rate': 1.8e-05, 'epoch': 1.8}\n",
      "{'loss': 0.3495, 'grad_norm': 10.375540733337402, 'learning_rate': 1.77e-05, 'epoch': 1.82}\n",
      "{'loss': 0.3236, 'grad_norm': 6.987428188323975, 'learning_rate': 1.74e-05, 'epoch': 1.84}\n",
      "{'loss': 0.2574, 'grad_norm': 9.969080924987793, 'learning_rate': 1.71e-05, 'epoch': 1.86}\n",
      "{'loss': 0.1456, 'grad_norm': 1.4709984064102173, 'learning_rate': 1.6800000000000002e-05, 'epoch': 1.88}\n",
      "{'loss': 0.1295, 'grad_norm': 4.837325572967529, 'learning_rate': 1.65e-05, 'epoch': 1.9}\n",
      "{'loss': 0.1928, 'grad_norm': 16.186630249023438, 'learning_rate': 1.62e-05, 'epoch': 1.92}\n",
      "{'loss': 0.145, 'grad_norm': 14.974921226501465, 'learning_rate': 1.59e-05, 'epoch': 1.94}\n",
      "{'loss': 0.1363, 'grad_norm': 7.1524200439453125, 'learning_rate': 1.56e-05, 'epoch': 1.96}\n",
      "{'loss': 0.0737, 'grad_norm': 7.254703044891357, 'learning_rate': 1.53e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0952, 'grad_norm': 1.1322647333145142, 'learning_rate': 1.5e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb701836213e40678798f21a65fe46ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1143685132265091, 'eval_accuracy': 0.9695, 'eval_runtime': 19.5292, 'eval_samples_per_second': 102.411, 'eval_steps_per_second': 1.639, 'epoch': 2.0}\n",
      "{'loss': 0.0472, 'grad_norm': 0.2822890281677246, 'learning_rate': 1.47e-05, 'epoch': 2.02}\n",
      "{'loss': 0.0964, 'grad_norm': 18.323644638061523, 'learning_rate': 1.44e-05, 'epoch': 2.04}\n",
      "{'loss': 0.084, 'grad_norm': 0.044632334262132645, 'learning_rate': 1.4099999999999999e-05, 'epoch': 2.06}\n",
      "{'loss': 0.1296, 'grad_norm': 1.074412226676941, 'learning_rate': 1.3800000000000002e-05, 'epoch': 2.08}\n",
      "{'loss': 0.0618, 'grad_norm': 1.4564831256866455, 'learning_rate': 1.3500000000000001e-05, 'epoch': 2.1}\n",
      "{'loss': 0.1122, 'grad_norm': 37.130157470703125, 'learning_rate': 1.32e-05, 'epoch': 2.12}\n",
      "{'loss': 0.1351, 'grad_norm': 25.169281005859375, 'learning_rate': 1.29e-05, 'epoch': 2.14}\n",
      "{'loss': 0.1527, 'grad_norm': 9.163354873657227, 'learning_rate': 1.26e-05, 'epoch': 2.16}\n",
      "{'loss': 0.095, 'grad_norm': 4.599025726318359, 'learning_rate': 1.2299999999999999e-05, 'epoch': 2.18}\n",
      "{'loss': 0.0991, 'grad_norm': 0.10002650320529938, 'learning_rate': 1.2e-05, 'epoch': 2.2}\n",
      "{'loss': 0.0923, 'grad_norm': 11.180315971374512, 'learning_rate': 1.1700000000000001e-05, 'epoch': 2.22}\n",
      "{'loss': 0.0984, 'grad_norm': 8.225102424621582, 'learning_rate': 1.1400000000000001e-05, 'epoch': 2.24}\n",
      "{'loss': 0.0581, 'grad_norm': 10.679737091064453, 'learning_rate': 1.11e-05, 'epoch': 2.26}\n",
      "{'loss': 0.1068, 'grad_norm': 26.607511520385742, 'learning_rate': 1.08e-05, 'epoch': 2.28}\n",
      "{'loss': 0.1105, 'grad_norm': 1.7523982524871826, 'learning_rate': 1.05e-05, 'epoch': 2.3}\n",
      "{'loss': 0.0912, 'grad_norm': 7.565013885498047, 'learning_rate': 1.02e-05, 'epoch': 2.32}\n",
      "{'loss': 0.0822, 'grad_norm': 8.52328109741211, 'learning_rate': 9.9e-06, 'epoch': 2.34}\n",
      "{'loss': 0.0537, 'grad_norm': 4.785096645355225, 'learning_rate': 9.600000000000001e-06, 'epoch': 2.36}\n",
      "{'loss': 0.0695, 'grad_norm': 0.203064426779747, 'learning_rate': 9.3e-06, 'epoch': 2.38}\n",
      "{'loss': 0.117, 'grad_norm': 2.03135347366333, 'learning_rate': 9e-06, 'epoch': 2.4}\n",
      "{'loss': 0.1386, 'grad_norm': 4.054952621459961, 'learning_rate': 8.7e-06, 'epoch': 2.42}\n",
      "{'loss': 0.1158, 'grad_norm': 5.38289213180542, 'learning_rate': 8.400000000000001e-06, 'epoch': 2.44}\n",
      "{'loss': 0.1282, 'grad_norm': 13.28642463684082, 'learning_rate': 8.1e-06, 'epoch': 2.46}\n",
      "{'loss': 0.1384, 'grad_norm': 1.1308428049087524, 'learning_rate': 7.8e-06, 'epoch': 2.48}\n",
      "{'loss': 0.1, 'grad_norm': 0.4359613358974457, 'learning_rate': 7.5e-06, 'epoch': 2.5}\n",
      "{'loss': 0.0371, 'grad_norm': 6.185772895812988, 'learning_rate': 7.2e-06, 'epoch': 2.52}\n",
      "{'loss': 0.0756, 'grad_norm': 8.739850044250488, 'learning_rate': 6.900000000000001e-06, 'epoch': 2.54}\n",
      "{'loss': 0.0924, 'grad_norm': 20.98519515991211, 'learning_rate': 6.6e-06, 'epoch': 2.56}\n",
      "{'loss': 0.0297, 'grad_norm': 1.0053635835647583, 'learning_rate': 6.3e-06, 'epoch': 2.58}\n",
      "{'loss': 0.131, 'grad_norm': 8.944790840148926, 'learning_rate': 6e-06, 'epoch': 2.6}\n",
      "{'loss': 0.1151, 'grad_norm': 16.195945739746094, 'learning_rate': 5.7000000000000005e-06, 'epoch': 2.62}\n",
      "{'loss': 0.1334, 'grad_norm': 1.3828917741775513, 'learning_rate': 5.4e-06, 'epoch': 2.64}\n",
      "{'loss': 0.0573, 'grad_norm': 0.19042277336120605, 'learning_rate': 5.1e-06, 'epoch': 2.66}\n",
      "{'loss': 0.1243, 'grad_norm': 0.011358925141394138, 'learning_rate': 4.800000000000001e-06, 'epoch': 2.68}\n",
      "{'loss': 0.08, 'grad_norm': 10.894198417663574, 'learning_rate': 4.5e-06, 'epoch': 2.7}\n",
      "{'loss': 0.1068, 'grad_norm': 9.44338321685791, 'learning_rate': 4.2000000000000004e-06, 'epoch': 2.72}\n",
      "{'loss': 0.1133, 'grad_norm': 22.491411209106445, 'learning_rate': 3.9e-06, 'epoch': 2.74}\n",
      "{'loss': 0.1391, 'grad_norm': 3.6027863025665283, 'learning_rate': 3.6e-06, 'epoch': 2.76}\n",
      "{'loss': 0.1387, 'grad_norm': 11.990738868713379, 'learning_rate': 3.3e-06, 'epoch': 2.78}\n",
      "{'loss': 0.1011, 'grad_norm': 26.91288948059082, 'learning_rate': 3e-06, 'epoch': 2.8}\n",
      "{'loss': 0.0582, 'grad_norm': 5.75139856338501, 'learning_rate': 2.7e-06, 'epoch': 2.82}\n",
      "{'loss': 0.0536, 'grad_norm': 0.09150714427232742, 'learning_rate': 2.4000000000000003e-06, 'epoch': 2.84}\n",
      "{'loss': 0.0922, 'grad_norm': 8.384474754333496, 'learning_rate': 2.1000000000000002e-06, 'epoch': 2.86}\n",
      "{'loss': 0.0987, 'grad_norm': 4.593133926391602, 'learning_rate': 1.8e-06, 'epoch': 2.88}\n",
      "{'loss': 0.0546, 'grad_norm': 0.40462273359298706, 'learning_rate': 1.5e-06, 'epoch': 2.9}\n",
      "{'loss': 0.0914, 'grad_norm': 5.892615795135498, 'learning_rate': 1.2000000000000002e-06, 'epoch': 2.92}\n",
      "{'loss': 0.0791, 'grad_norm': 5.239255428314209, 'learning_rate': 9e-07, 'epoch': 2.94}\n",
      "{'loss': 0.0641, 'grad_norm': 1.5290411710739136, 'learning_rate': 6.000000000000001e-07, 'epoch': 2.96}\n",
      "{'loss': 0.1491, 'grad_norm': 3.3453099727630615, 'learning_rate': 3.0000000000000004e-07, 'epoch': 2.98}\n",
      "{'loss': 0.1903, 'grad_norm': 0.04474087804555893, 'learning_rate': 0.0, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6c5d1b55ef3416db39c7ab0933cb2a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11268848180770874, 'eval_accuracy': 0.971, 'eval_runtime': 19.167, 'eval_samples_per_second': 104.346, 'eval_steps_per_second': 1.67, 'epoch': 3.0}\n",
      "{'train_runtime': 1081.6431, 'train_samples_per_second': 22.188, 'train_steps_per_second': 1.387, 'train_loss': 0.15802534715334574, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f2faa1404df456a985598a301ee6540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Accuracy: 0.971\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml_final_project_env/lib/python3.8/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "182575d2556d4b53bb3029040687cfe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0583, 'grad_norm': 3.755652904510498, 'learning_rate': 6.000000000000001e-07, 'epoch': 0.02}\n",
      "{'loss': 0.1048, 'grad_norm': 0.2616158723831177, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.04}\n",
      "{'loss': 0.0762, 'grad_norm': 1.38130784034729, 'learning_rate': 1.8e-06, 'epoch': 0.06}\n",
      "{'loss': 0.0884, 'grad_norm': 1.2184561491012573, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.08}\n",
      "{'loss': 0.204, 'grad_norm': 13.52298355102539, 'learning_rate': 3e-06, 'epoch': 0.1}\n",
      "{'loss': 0.0217, 'grad_norm': 17.444320678710938, 'learning_rate': 3.6e-06, 'epoch': 0.12}\n",
      "{'loss': 0.0878, 'grad_norm': 1.1931358575820923, 'learning_rate': 4.2000000000000004e-06, 'epoch': 0.14}\n",
      "{'loss': 0.0246, 'grad_norm': 3.9978559017181396, 'learning_rate': 4.800000000000001e-06, 'epoch': 0.16}\n",
      "{'loss': 0.0634, 'grad_norm': 0.4461985230445862, 'learning_rate': 5.4e-06, 'epoch': 0.18}\n",
      "{'loss': 0.1373, 'grad_norm': 4.974908828735352, 'learning_rate': 6e-06, 'epoch': 0.2}\n",
      "{'loss': 0.0314, 'grad_norm': 0.6967633962631226, 'learning_rate': 6.6e-06, 'epoch': 0.22}\n",
      "{'loss': 0.0696, 'grad_norm': 0.7816298007965088, 'learning_rate': 7.2e-06, 'epoch': 0.24}\n",
      "{'loss': 0.1502, 'grad_norm': 0.02189674973487854, 'learning_rate': 7.8e-06, 'epoch': 0.26}\n",
      "{'loss': 0.0767, 'grad_norm': 1.7994844913482666, 'learning_rate': 8.400000000000001e-06, 'epoch': 0.28}\n",
      "{'loss': 0.0517, 'grad_norm': 0.49031153321266174, 'learning_rate': 9e-06, 'epoch': 0.3}\n",
      "{'loss': 0.1532, 'grad_norm': 0.34374934434890747, 'learning_rate': 9.600000000000001e-06, 'epoch': 0.32}\n",
      "{'loss': 0.045, 'grad_norm': 0.11878007650375366, 'learning_rate': 1.02e-05, 'epoch': 0.34}\n",
      "{'loss': 0.0627, 'grad_norm': 3.9653589725494385, 'learning_rate': 1.08e-05, 'epoch': 0.36}\n",
      "{'loss': 0.044, 'grad_norm': 0.46601584553718567, 'learning_rate': 1.1400000000000001e-05, 'epoch': 0.38}\n",
      "{'loss': 0.0734, 'grad_norm': 11.772483825683594, 'learning_rate': 1.2e-05, 'epoch': 0.4}\n",
      "{'loss': 0.0278, 'grad_norm': 6.524909973144531, 'learning_rate': 1.26e-05, 'epoch': 0.42}\n",
      "{'loss': 0.0784, 'grad_norm': 23.974388122558594, 'learning_rate': 1.32e-05, 'epoch': 0.44}\n",
      "{'loss': 0.0727, 'grad_norm': 1.1010688543319702, 'learning_rate': 1.3800000000000002e-05, 'epoch': 0.46}\n",
      "{'loss': 0.071, 'grad_norm': 1.0484181642532349, 'learning_rate': 1.44e-05, 'epoch': 0.48}\n",
      "{'loss': 0.0762, 'grad_norm': 23.71977996826172, 'learning_rate': 1.5e-05, 'epoch': 0.5}\n",
      "{'loss': 0.0838, 'grad_norm': 0.12030533701181412, 'learning_rate': 1.56e-05, 'epoch': 0.52}\n",
      "{'loss': 0.1344, 'grad_norm': 9.710994720458984, 'learning_rate': 1.62e-05, 'epoch': 0.54}\n",
      "{'loss': 0.0327, 'grad_norm': 0.3825291097164154, 'learning_rate': 1.6800000000000002e-05, 'epoch': 0.56}\n",
      "{'loss': 0.0906, 'grad_norm': 6.944570541381836, 'learning_rate': 1.74e-05, 'epoch': 0.58}\n",
      "{'loss': 0.1241, 'grad_norm': 0.20758923888206482, 'learning_rate': 1.8e-05, 'epoch': 0.6}\n",
      "{'loss': 0.0936, 'grad_norm': 0.1486695408821106, 'learning_rate': 1.86e-05, 'epoch': 0.62}\n",
      "{'loss': 0.0466, 'grad_norm': 2.8575797080993652, 'learning_rate': 1.9200000000000003e-05, 'epoch': 0.64}\n",
      "{'loss': 0.1411, 'grad_norm': 5.227142333984375, 'learning_rate': 1.98e-05, 'epoch': 0.66}\n",
      "{'loss': 0.048, 'grad_norm': 6.306093692779541, 'learning_rate': 2.04e-05, 'epoch': 0.68}\n",
      "{'loss': 0.1087, 'grad_norm': 0.24547642469406128, 'learning_rate': 2.1e-05, 'epoch': 0.7}\n",
      "{'loss': 0.2144, 'grad_norm': 14.697086334228516, 'learning_rate': 2.16e-05, 'epoch': 0.72}\n",
      "{'loss': 0.0871, 'grad_norm': 0.6906833052635193, 'learning_rate': 2.22e-05, 'epoch': 0.74}\n",
      "{'loss': 0.2415, 'grad_norm': 10.434796333312988, 'learning_rate': 2.2800000000000002e-05, 'epoch': 0.76}\n",
      "{'loss': 0.0796, 'grad_norm': 2.687199354171753, 'learning_rate': 2.3400000000000003e-05, 'epoch': 0.78}\n",
      "{'loss': 0.1114, 'grad_norm': 0.7920563220977783, 'learning_rate': 2.4e-05, 'epoch': 0.8}\n",
      "{'loss': 0.1126, 'grad_norm': 0.3336138427257538, 'learning_rate': 2.4599999999999998e-05, 'epoch': 0.82}\n",
      "{'loss': 0.0624, 'grad_norm': 0.4557308852672577, 'learning_rate': 2.52e-05, 'epoch': 0.84}\n",
      "{'loss': 0.0202, 'grad_norm': 0.6861662864685059, 'learning_rate': 2.58e-05, 'epoch': 0.86}\n",
      "{'loss': 0.1099, 'grad_norm': 6.425584316253662, 'learning_rate': 2.64e-05, 'epoch': 0.88}\n",
      "{'loss': 0.2307, 'grad_norm': 11.312336921691895, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.9}\n",
      "{'loss': 0.1119, 'grad_norm': 9.524662017822266, 'learning_rate': 2.7600000000000003e-05, 'epoch': 0.92}\n",
      "{'loss': 0.1799, 'grad_norm': 2.962855815887451, 'learning_rate': 2.8199999999999998e-05, 'epoch': 0.94}\n",
      "{'loss': 0.0895, 'grad_norm': 16.369579315185547, 'learning_rate': 2.88e-05, 'epoch': 0.96}\n",
      "{'loss': 0.1752, 'grad_norm': 0.036697935312986374, 'learning_rate': 2.94e-05, 'epoch': 0.98}\n",
      "{'loss': 0.1616, 'grad_norm': 3.7255468368530273, 'learning_rate': 3e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "585cb646010b44e69f05baed1a27b95c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07846000045537949, 'eval_accuracy': 0.978, 'eval_runtime': 19.673, 'eval_samples_per_second': 101.662, 'eval_steps_per_second': 1.627, 'epoch': 1.0}\n",
      "{'loss': 0.0805, 'grad_norm': 1.5671218633651733, 'learning_rate': 2.97e-05, 'epoch': 1.02}\n",
      "{'loss': 0.0861, 'grad_norm': 0.5514340400695801, 'learning_rate': 2.94e-05, 'epoch': 1.04}\n",
      "{'loss': 0.0099, 'grad_norm': 1.6445542573928833, 'learning_rate': 2.91e-05, 'epoch': 1.06}\n",
      "{'loss': 0.112, 'grad_norm': 7.233278751373291, 'learning_rate': 2.88e-05, 'epoch': 1.08}\n",
      "{'loss': 0.0735, 'grad_norm': 0.03899127617478371, 'learning_rate': 2.8499999999999998e-05, 'epoch': 1.1}\n",
      "{'loss': 0.0214, 'grad_norm': 1.0770714282989502, 'learning_rate': 2.8199999999999998e-05, 'epoch': 1.12}\n",
      "{'loss': 0.2905, 'grad_norm': 4.401209354400635, 'learning_rate': 2.79e-05, 'epoch': 1.14}\n",
      "{'loss': 0.0778, 'grad_norm': 0.03963104635477066, 'learning_rate': 2.7600000000000003e-05, 'epoch': 1.16}\n",
      "{'loss': 0.1446, 'grad_norm': 9.44499397277832, 'learning_rate': 2.7300000000000003e-05, 'epoch': 1.18}\n",
      "{'loss': 0.1318, 'grad_norm': 0.42425423860549927, 'learning_rate': 2.7000000000000002e-05, 'epoch': 1.2}\n",
      "{'loss': 0.0863, 'grad_norm': 3.575227737426758, 'learning_rate': 2.6700000000000002e-05, 'epoch': 1.22}\n",
      "{'loss': 0.134, 'grad_norm': 5.886331558227539, 'learning_rate': 2.64e-05, 'epoch': 1.24}\n",
      "{'loss': 0.1244, 'grad_norm': 12.105703353881836, 'learning_rate': 2.61e-05, 'epoch': 1.26}\n",
      "{'loss': 0.0739, 'grad_norm': 0.24614940583705902, 'learning_rate': 2.58e-05, 'epoch': 1.28}\n",
      "{'loss': 0.0376, 'grad_norm': 11.45152759552002, 'learning_rate': 2.55e-05, 'epoch': 1.3}\n",
      "{'loss': 0.1543, 'grad_norm': 11.863446235656738, 'learning_rate': 2.52e-05, 'epoch': 1.32}\n",
      "{'loss': 0.0954, 'grad_norm': 0.649248480796814, 'learning_rate': 2.49e-05, 'epoch': 1.34}\n",
      "{'loss': 0.0494, 'grad_norm': 1.0722789764404297, 'learning_rate': 2.4599999999999998e-05, 'epoch': 1.36}\n",
      "{'loss': 0.0574, 'grad_norm': 0.08704721927642822, 'learning_rate': 2.43e-05, 'epoch': 1.38}\n",
      "{'loss': 0.1009, 'grad_norm': 11.184913635253906, 'learning_rate': 2.4e-05, 'epoch': 1.4}\n",
      "{'loss': 0.1078, 'grad_norm': 0.273226261138916, 'learning_rate': 2.37e-05, 'epoch': 1.42}\n",
      "{'loss': 0.1379, 'grad_norm': 10.275458335876465, 'learning_rate': 2.3400000000000003e-05, 'epoch': 1.44}\n",
      "{'loss': 0.0208, 'grad_norm': 1.1746724843978882, 'learning_rate': 2.3100000000000002e-05, 'epoch': 1.46}\n",
      "{'loss': 0.0739, 'grad_norm': 1.717283010482788, 'learning_rate': 2.2800000000000002e-05, 'epoch': 1.48}\n",
      "{'loss': 0.0597, 'grad_norm': 0.43682006001472473, 'learning_rate': 2.25e-05, 'epoch': 1.5}\n",
      "{'loss': 0.0472, 'grad_norm': 1.2789009809494019, 'learning_rate': 2.22e-05, 'epoch': 1.52}\n",
      "{'loss': 0.0443, 'grad_norm': 0.3450242280960083, 'learning_rate': 2.19e-05, 'epoch': 1.54}\n",
      "{'loss': 0.087, 'grad_norm': 14.498360633850098, 'learning_rate': 2.16e-05, 'epoch': 1.56}\n",
      "{'loss': 0.128, 'grad_norm': 17.155763626098633, 'learning_rate': 2.13e-05, 'epoch': 1.58}\n",
      "{'loss': 0.063, 'grad_norm': 3.511890172958374, 'learning_rate': 2.1e-05, 'epoch': 1.6}\n",
      "{'loss': 0.0944, 'grad_norm': 3.3597910404205322, 'learning_rate': 2.07e-05, 'epoch': 1.62}\n",
      "{'loss': 0.11, 'grad_norm': 0.23277302086353302, 'learning_rate': 2.04e-05, 'epoch': 1.64}\n",
      "{'loss': 0.055, 'grad_norm': 2.573452949523926, 'learning_rate': 2.01e-05, 'epoch': 1.66}\n",
      "{'loss': 0.1155, 'grad_norm': 3.6684048175811768, 'learning_rate': 1.98e-05, 'epoch': 1.68}\n",
      "{'loss': 0.1262, 'grad_norm': 18.122804641723633, 'learning_rate': 1.95e-05, 'epoch': 1.7}\n",
      "{'loss': 0.1752, 'grad_norm': 0.21186700463294983, 'learning_rate': 1.9200000000000003e-05, 'epoch': 1.72}\n",
      "{'loss': 0.114, 'grad_norm': 3.6491990089416504, 'learning_rate': 1.8900000000000002e-05, 'epoch': 1.74}\n",
      "{'loss': 0.0632, 'grad_norm': 0.9134953618049622, 'learning_rate': 1.86e-05, 'epoch': 1.76}\n",
      "{'loss': 0.0207, 'grad_norm': 1.9962718486785889, 'learning_rate': 1.83e-05, 'epoch': 1.78}\n",
      "{'loss': 0.0347, 'grad_norm': 3.6415762901306152, 'learning_rate': 1.8e-05, 'epoch': 1.8}\n",
      "{'loss': 0.0689, 'grad_norm': 5.550427436828613, 'learning_rate': 1.77e-05, 'epoch': 1.82}\n",
      "{'loss': 0.1039, 'grad_norm': 18.073631286621094, 'learning_rate': 1.74e-05, 'epoch': 1.84}\n",
      "{'loss': 0.1918, 'grad_norm': 5.646730899810791, 'learning_rate': 1.71e-05, 'epoch': 1.86}\n",
      "{'loss': 0.1278, 'grad_norm': 4.37973165512085, 'learning_rate': 1.6800000000000002e-05, 'epoch': 1.88}\n",
      "{'loss': 0.0712, 'grad_norm': 15.113008499145508, 'learning_rate': 1.65e-05, 'epoch': 1.9}\n",
      "{'loss': 0.0557, 'grad_norm': 18.53162956237793, 'learning_rate': 1.62e-05, 'epoch': 1.92}\n",
      "{'loss': 0.0415, 'grad_norm': 7.9717936515808105, 'learning_rate': 1.59e-05, 'epoch': 1.94}\n",
      "{'loss': 0.0478, 'grad_norm': 0.2186013013124466, 'learning_rate': 1.56e-05, 'epoch': 1.96}\n",
      "{'loss': 0.0483, 'grad_norm': 5.383123397827148, 'learning_rate': 1.53e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0446, 'grad_norm': 0.37393656373023987, 'learning_rate': 1.5e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39adae1d12f8462690bcd7f0898b5380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09446899592876434, 'eval_accuracy': 0.978, 'eval_runtime': 19.5676, 'eval_samples_per_second': 102.21, 'eval_steps_per_second': 1.635, 'epoch': 2.0}\n",
      "{'loss': 0.0029, 'grad_norm': 0.07137056440114975, 'learning_rate': 1.47e-05, 'epoch': 2.02}\n",
      "{'loss': 0.0292, 'grad_norm': 0.727835476398468, 'learning_rate': 1.44e-05, 'epoch': 2.04}\n",
      "{'loss': 0.0116, 'grad_norm': 0.9934439063072205, 'learning_rate': 1.4099999999999999e-05, 'epoch': 2.06}\n",
      "{'loss': 0.1101, 'grad_norm': 1.3438656330108643, 'learning_rate': 1.3800000000000002e-05, 'epoch': 2.08}\n",
      "{'loss': 0.0441, 'grad_norm': 0.31113654375076294, 'learning_rate': 1.3500000000000001e-05, 'epoch': 2.1}\n",
      "{'loss': 0.0381, 'grad_norm': 0.3861263692378998, 'learning_rate': 1.32e-05, 'epoch': 2.12}\n",
      "{'loss': 0.0626, 'grad_norm': 4.118800640106201, 'learning_rate': 1.29e-05, 'epoch': 2.14}\n",
      "{'loss': 0.0276, 'grad_norm': 8.797332763671875, 'learning_rate': 1.26e-05, 'epoch': 2.16}\n",
      "{'loss': 0.0354, 'grad_norm': 0.08645141124725342, 'learning_rate': 1.2299999999999999e-05, 'epoch': 2.18}\n",
      "{'loss': 0.0532, 'grad_norm': 0.13796879351139069, 'learning_rate': 1.2e-05, 'epoch': 2.2}\n",
      "{'loss': 0.0637, 'grad_norm': 10.038036346435547, 'learning_rate': 1.1700000000000001e-05, 'epoch': 2.22}\n",
      "{'loss': 0.0332, 'grad_norm': 4.8630828857421875, 'learning_rate': 1.1400000000000001e-05, 'epoch': 2.24}\n",
      "{'loss': 0.031, 'grad_norm': 0.6454816460609436, 'learning_rate': 1.11e-05, 'epoch': 2.26}\n",
      "{'loss': 0.0273, 'grad_norm': 0.403466135263443, 'learning_rate': 1.08e-05, 'epoch': 2.28}\n",
      "{'loss': 0.1455, 'grad_norm': 9.135747909545898, 'learning_rate': 1.05e-05, 'epoch': 2.3}\n",
      "{'loss': 0.0188, 'grad_norm': 0.03249766305088997, 'learning_rate': 1.02e-05, 'epoch': 2.32}\n",
      "{'loss': 0.0755, 'grad_norm': 0.2972598671913147, 'learning_rate': 9.9e-06, 'epoch': 2.34}\n",
      "{'loss': 0.0518, 'grad_norm': 9.247958183288574, 'learning_rate': 9.600000000000001e-06, 'epoch': 2.36}\n",
      "{'loss': 0.0502, 'grad_norm': 22.73366355895996, 'learning_rate': 9.3e-06, 'epoch': 2.38}\n",
      "{'loss': 0.0576, 'grad_norm': 16.625782012939453, 'learning_rate': 9e-06, 'epoch': 2.4}\n",
      "{'loss': 0.0489, 'grad_norm': 0.2256338894367218, 'learning_rate': 8.7e-06, 'epoch': 2.42}\n",
      "{'loss': 0.0355, 'grad_norm': 0.6765515208244324, 'learning_rate': 8.400000000000001e-06, 'epoch': 2.44}\n",
      "{'loss': 0.0116, 'grad_norm': 1.0081344842910767, 'learning_rate': 8.1e-06, 'epoch': 2.46}\n",
      "{'loss': 0.0738, 'grad_norm': 92.02244567871094, 'learning_rate': 7.8e-06, 'epoch': 2.48}\n",
      "{'loss': 0.0448, 'grad_norm': 12.250904083251953, 'learning_rate': 7.5e-06, 'epoch': 2.5}\n",
      "{'loss': 0.008, 'grad_norm': 0.34913721680641174, 'learning_rate': 7.2e-06, 'epoch': 2.52}\n",
      "{'loss': 0.0096, 'grad_norm': 3.7561967372894287, 'learning_rate': 6.900000000000001e-06, 'epoch': 2.54}\n",
      "{'loss': 0.0128, 'grad_norm': 1.6819607019424438, 'learning_rate': 6.6e-06, 'epoch': 2.56}\n",
      "{'loss': 0.0036, 'grad_norm': 0.22355876863002777, 'learning_rate': 6.3e-06, 'epoch': 2.58}\n",
      "{'loss': 0.0834, 'grad_norm': 10.233956336975098, 'learning_rate': 6e-06, 'epoch': 2.6}\n",
      "{'loss': 0.0505, 'grad_norm': 4.258701801300049, 'learning_rate': 5.7000000000000005e-06, 'epoch': 2.62}\n",
      "{'loss': 0.03, 'grad_norm': 2.0661656856536865, 'learning_rate': 5.4e-06, 'epoch': 2.64}\n",
      "{'loss': 0.0328, 'grad_norm': 0.05202189460396767, 'learning_rate': 5.1e-06, 'epoch': 2.66}\n",
      "{'loss': 0.0197, 'grad_norm': 0.07717283070087433, 'learning_rate': 4.800000000000001e-06, 'epoch': 2.68}\n",
      "{'loss': 0.0802, 'grad_norm': 0.12320209294557571, 'learning_rate': 4.5e-06, 'epoch': 2.7}\n",
      "{'loss': 0.0832, 'grad_norm': 0.1531139612197876, 'learning_rate': 4.2000000000000004e-06, 'epoch': 2.72}\n",
      "{'loss': 0.0561, 'grad_norm': 1.7957878112792969, 'learning_rate': 3.9e-06, 'epoch': 2.74}\n",
      "{'loss': 0.0677, 'grad_norm': 8.556180000305176, 'learning_rate': 3.6e-06, 'epoch': 2.76}\n",
      "{'loss': 0.0601, 'grad_norm': 0.13891692459583282, 'learning_rate': 3.3e-06, 'epoch': 2.78}\n",
      "{'loss': 0.0464, 'grad_norm': 1.5247743129730225, 'learning_rate': 3e-06, 'epoch': 2.8}\n",
      "{'loss': 0.0095, 'grad_norm': 1.8879547119140625, 'learning_rate': 2.7e-06, 'epoch': 2.82}\n",
      "{'loss': 0.0178, 'grad_norm': 0.026970168575644493, 'learning_rate': 2.4000000000000003e-06, 'epoch': 2.84}\n",
      "{'loss': 0.0576, 'grad_norm': 11.997296333312988, 'learning_rate': 2.1000000000000002e-06, 'epoch': 2.86}\n",
      "{'loss': 0.049, 'grad_norm': 0.1161060556769371, 'learning_rate': 1.8e-06, 'epoch': 2.88}\n",
      "{'loss': 0.0209, 'grad_norm': 1.1495240926742554, 'learning_rate': 1.5e-06, 'epoch': 2.9}\n",
      "{'loss': 0.02, 'grad_norm': 14.966506958007812, 'learning_rate': 1.2000000000000002e-06, 'epoch': 2.92}\n",
      "{'loss': 0.0392, 'grad_norm': 1.0295442342758179, 'learning_rate': 9e-07, 'epoch': 2.94}\n",
      "{'loss': 0.0512, 'grad_norm': 15.35071086883545, 'learning_rate': 6.000000000000001e-07, 'epoch': 2.96}\n",
      "{'loss': 0.138, 'grad_norm': 0.4877311587333679, 'learning_rate': 3.0000000000000004e-07, 'epoch': 2.98}\n",
      "{'loss': 0.0275, 'grad_norm': 0.02220168150961399, 'learning_rate': 0.0, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4eed7bfd06f429cae910e3e9ac3d4dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0890464335680008, 'eval_accuracy': 0.9805, 'eval_runtime': 512.3574, 'eval_samples_per_second': 3.904, 'eval_steps_per_second': 0.062, 'epoch': 3.0}\n",
      "{'train_runtime': 1553.92, 'train_samples_per_second': 15.445, 'train_steps_per_second': 0.965, 'train_loss': 0.07681357027838627, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c21e8b606a454fbcb01bb45a8f24de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Accuracy: 0.978\n",
      "Average Cross-Validation Accuracy: 0.9008\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 89\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Cross-Validation Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maverage_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Load the test data\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m test_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m test_text \u001b[38;5;241m=\u001b[39m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()  \u001b[38;5;66;03m# Assuming the text column is named 'text'\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# Tokenize the test data\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_final_project_env/lib/python3.8/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_final_project_env/lib/python3.8/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_final_project_env/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_final_project_env/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_final_project_env/lib/python3.8/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test.csv'"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(set(train_label)))\n",
    "\n",
    "# Define cross-validation strategy\n",
    "strat_k_fold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Initialize lists to store results\n",
    "accuracies = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(strat_k_fold.split(train_text, train_label)):\n",
    "\n",
    "    # Split the data\n",
    "    X_train_fold, X_val_fold = np.array(train_text)[train_idx], np.array(train_text)[val_idx]\n",
    "    y_train_fold, y_val_fold = np.array(train_label)[train_idx], np.array(train_label)[val_idx]\n",
    "\n",
    "    # Tokenize the data\n",
    "    train_encodings = tokenizer(X_train_fold.tolist(), truncation=True, padding=True, max_length=128)\n",
    "    val_encodings = tokenizer(X_val_fold.tolist(), truncation=True, padding=True, max_length=128)\n",
    "\n",
    "    class EmotionDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, encodings, labels):\n",
    "            self.encodings = encodings\n",
    "            self.labels = labels\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "            item['labels'] = torch.tensor(self.labels[idx])\n",
    "            return item\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.labels)\n",
    "\n",
    "    train_dataset = EmotionDataset(train_encodings, y_train_fold.tolist())\n",
    "    val_dataset = EmotionDataset(val_encodings, y_val_fold.tolist())\n",
    "\n",
    "    # Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=64,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        learning_rate=5e-5,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "    )\n",
    "\n",
    "    # Initialize Trainer\n",
    "    # Initialize Trainer with EarlyStoppingCallback\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=lambda p: {\"accuracy\": accuracy_score(p.label_ids, p.predictions.argmax(-1))},\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "    )\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = trainer.predict(val_dataset)\n",
    "    preds = np.argmax(y_pred.predictions, axis=1)\n",
    "    accuracy = accuracy_score(y_val_fold, preds)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"Fold {fold + 1} Accuracy: {accuracy}\")\n",
    "\n",
    "# Calculate average accuracy\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"Average Cross-Validation Accuracy: {average_accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "386de030cabc449caacdd03428de3702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/235 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_encodings = tokenizer(test_text, truncation=True, padding=True, max_length=128)\n",
    "test_dataset = EmotionDataset(test_encodings, [0]*len(test_text))  # Dummy labels\n",
    "\n",
    "# Generate predictions for the test dataset using BERT model\n",
    "predictions = trainer.predict(test_dataset)\n",
    "bert_predictions = predictions.predictions.argmax(-1)\n",
    "\n",
    "# Save BERT predictions to CSV\n",
    "bert_submission = pd.DataFrame({'id': range(len(bert_predictions)), 'label': bert_predictions})\n",
    "bert_submission.to_csv('../submission/bert_cross_val_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "009aec4ae2ca4206bd83530f77660dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([16])) must be the same as input size (torch.Size([16, 28]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Generate predictions for the validation dataset using BERT model\u001b[39;00m\n\u001b[1;32m      5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mpredict(test_dataset)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_final_project_env/lib/python3.8/site-packages/transformers/trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_final_project_env/lib/python3.8/site-packages/transformers/trainer.py:2388\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2387\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2388\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2391\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2392\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2393\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2394\u001b[0m ):\n\u001b[1;32m   2395\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2396\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_final_project_env/lib/python3.8/site-packages/transformers/trainer.py:3485\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3484\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3485\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3487\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3489\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3490\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3491\u001b[0m ):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_final_project_env/lib/python3.8/site-packages/transformers/trainer.py:3532\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3530\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3531\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3532\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3533\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3534\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_final_project_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_final_project_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_final_project_env/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:1734\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1732\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mproblem_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti_label_classification\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1733\u001b[0m         loss_fct \u001b[38;5;241m=\u001b[39m BCEWithLogitsLoss()\n\u001b[0;32m-> 1734\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1736\u001b[0m     output \u001b[38;5;241m=\u001b[39m (logits,) \u001b[38;5;241m+\u001b[39m outputs[\u001b[38;5;241m2\u001b[39m:]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_final_project_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_final_project_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_final_project_env/lib/python3.8/site-packages/torch/nn/modules/loss.py:734\u001b[0m, in \u001b[0;36mBCEWithLogitsLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m                                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_final_project_env/lib/python3.8/site-packages/torch/nn/functional.py:3242\u001b[0m, in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3239\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()):\n\u001b[0;32m-> 3242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) must be the same as input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbinary_cross_entropy_with_logits(\u001b[38;5;28minput\u001b[39m, target, weight, pos_weight, reduction_enum)\n",
      "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([16])) must be the same as input size (torch.Size([16, 28]))"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Generate predictions for the validation dataset using BERT model\n",
    "predictions = trainer.predict(test_dataset)\n",
    "bert_predictions = predictions.predictions.argmax(-1)\n",
    "\n",
    "accuracy_bert = accuracy_score(y_val, bert_predictions)\n",
    "print(f'BERT Accuracy: {accuracy_bert}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.2 Explanation in Words:</h3><p>\n",
    "You need to answer the following questions in a markdown cell after this cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.1 How much did you manage to improve performance on the test set? Did you beat \"Zero Hero\" in Kaggle? (Please include a screenshot of Kaggle Submission)\n",
    "\n",
    "With our SVM approach, we managed to achieve an accuracy of 0.68600, but with our approach using BERT, we managed to raise the accuracy by 0.0844 to 0.77040. Below is a screenshot of the the kaggle submission accuracy on the leaderboard, our team name is \"Lebron James\":\n",
    "\n",
    "2.2.2 Please explain in detail how you achieved this and what you did specifically and why you tried this.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 3: Kaggle Submission</h2><p>\n",
    "You need to generate a prediction CSV using the following cell from your trained model and submit the direct output of your code to Kaggle. The results should be presented in two columns in csv format: the first column is the data id (0-14999) and the second column includes the predictions for the test set. The first column must be named id and the second column must be named label (otherwise your submission will fail). A sample predication file can be downloaded from Kaggle for each problem. \n",
    "We provide how to save a csv file if you are running Notebook on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "id = range(15000)\n",
    "# Vectorize the test data and make predictions\n",
    "svm_predictions = svm_model.predict(vectorizer_tfidf.transform(test_text))\n",
    "nb_predictions = nb_model.predict(vectorizer_bow.transform(test_text))\n",
    "\n",
    "# Save predictions to CSV\n",
    "svm_submission = pd.DataFrame({'id': id, 'label': svm_predictions})\n",
    "nb_submission = pd.DataFrame({'id': id, 'label': nb_predictions})\n",
    "\n",
    "svm_submission.to_csv('../submission/svm_predictions.csv', index=False)\n",
    "nb_submission.to_csv('../submission/nb_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save BERT predictions to CSV\n",
    "# Tokenize the test data\n",
    "test_encodings = tokenizer(test_text.tolist(), truncation=True, padding=True, max_length=128)\n",
    "test_dataset = EmotionDataset(test_encodings, [0]*len(test_text))  # Dummy labels\n",
    "\n",
    "# Generate predictions for the test dataset using BERT model\n",
    "predictions = trainer.predict(test_dataset)\n",
    "bert_predictions = predictions.predictions.argmax(-1)\n",
    "\n",
    "# Save BERT predictions to CSV\n",
    "bert_submission = pd.DataFrame({'id': range(len(bert_predictions)), 'label': bert_predictions})\n",
    "bert_submission.to_csv('../submission/bert_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 4: Resources and Literature Used</h2><p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please cite the papers and open resources you used.\n",
    "\n",
    "Papers:\n",
    "- SVM paper: https://www.cs.cornell.edu/~tj/publications/joachims_98a.pdf\n",
    "\n",
    "scikit-learn documentation used:\n",
    "- TfidfVectorizer: https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "- CountVectorizer: https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "- MultinomialNB: https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
    "- SVC: https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVC.html\n",
    "- GridSearchCV: https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "- train_test_split: https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/docs/transformers/en/model_doc/bert \n",
    "https://arxiv.org/pdf/1810.04805\n",
    "https://huggingface.co/docs/transformers/en/index\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
